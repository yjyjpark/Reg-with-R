[["index.html", "R에 의한 회귀분석 소개하기", " R에 의한 회귀분석 박동련 2023-08-26 소개하기 "],["ch1.html", "1 장 회귀모형 1.1 반응변수와 설명변수 사이의 관계 설정 1.2 회귀모형의 설정 1.3 회귀모형의 사용 1.4 R의 역할", " 1 장 회귀모형 사회현상, 자연현상, 경영현상이나 경제현상 등을 측정한 변수들의 변동은 그 현상과 관련된 여러 변수들과 관련이 있다고 볼 수 있다. 어떤 현상을 과학적 시각으로 셜명하기 위해서는 해당 현상과 관련이 있는 변수들 사이의 관계를 설명하기 위한 적절한 모형을 설정해야 할 것이다. 회귀분석(regression analysis)이란 특정 현상과 그 현상에 영향을 주거나 혹은 관련이 있는 변수들 사이의 관계를 분석하고 모형화하기 위한 통계적 기법이다. 회귀분석에서는 변수들 사이의 함수관계를 이론적 근거나 경험적 판단에 의해서 설정하고, 관측된 자료에 의해서 함수관계를 추정해서 변수들 사이의 관계를 설명하거나 예측하는데 사용된다. 따라서 회귀분석은 사회과학, 공학, 물리학, 생물학, 경영학, 경제학, 의학 등 거의 모든 학문 분야에서 가장 널리 사용되고 있는 통계적 분석 방법인 것이다. 회귀모형을 설정할 때 우리가 관심이 있는 특정 현상의 변동을 나타내는 변수를 종속변수(dependent variable) 혹은 반응변수(response variable)라고 하며, 일반적으로 \\(Y\\)로 표시한다. 반응변수가 나타내는 특정 현상에 연관되어 있을 것으로 판단되는 변수를 독립변수(independent variable) 혹은 설명변수(explanatory variable)라고 하고, 일반적으로 \\(X\\)로 표시한다. 만일 설명변수의 수가 \\(k\\)개 있다고 하면 \\(X_{1}, X_{2}, \\ldots, X_{k}\\)로 표시한다. 예를 들어, 회사 마케팅 부서에서 특정 제품의 매출액 변동을 예측할 수 있는 모형을 설정하고자 할 때 제품의 매출액 변동에 영향을 줄 수 있는 변수들로 광고비 지출액, 가격수준, 기술수준, 디자인 선호수준, 소득수준, 영엽사원의 수, 경쟁제품의 수 등을 생각할 수 있는데, 이 경우에 반응변수는 제품의 매출액이 되고, 광고비 지출액 등 나머지 변수들은 설명변수가 된다. 또 다른 예로써 투자자문회사에서 고객의 투자행위에 대한 예측모형을 개발할 때 투자행위에 영향을 미칠 수 있는 변수들로 연소득 수준, 미래 경제상황지수, 시장 이자율 등을 이용하게 되는데, 여기에서 반응변수는 고개들의 투자액이 되고, 연소득 수준 등은 설명변수가 된다. 회귀모형은 모형에 포힘되는 설명변수가 한 개인 경우에는 단순회귀모형(simple regression model)이라고 하고, 두 개 이상의 설명변수가 모형에 포함되는 경우에는 다중회귀모형(multiple regression model)이라고 한다. 1.1 반응변수와 설명변수 사이의 관계 설정 반응변수와 설명변수 사이의 관계는 일반적으로 결정적 관계(deterministic relation)와 확률적 관계(stochastic relation)로 구분해 볼 수 있다. 결정적 관계는 반응변수와 설명변수 사이에 정확한 수학적 함수관계가 성립되는 경우를 의미하는 것으로 \\(Y=f(X)\\)와 같이 표시할 수 있다. 여기에서 함수 \\(f\\) 는 직선, 곡선 혹은 더 복잡한 형태의 함수식이 될 수 있다. 결정적 관계에서는 설명변수의 값이 주어지면, 함수 \\(f\\) 에 의하여 대응되는 반응변수의 값이 유일하게 결정된다. 예를 들어, 제품의 판매단가가 2만원 일 때 판매개수(\\(X\\))와 매출액(\\(Y\\)) 사이의 관계는 \\(Y=2X\\)로 표현되는 결정적 관계가 성립한다. 반면에 확률적 관계는 설명변수로 반응변수의 변동을 100% 설명할 수 없는 관계를 의미한다. 예를 들어, 특정 제품의 매출액(\\(Y\\))과 광고비 지출액(\\(X\\)) 사이의 관계를 생각해 보자. 일반적으로 광고비 지출을 증가시키면 매출액이 증가하겠지만, 광고비 지출액만으로 매출액의 변동을 100% 설명하는 것은 불가능하다. 가격수준, 기술수준, 디자인 선호수준, 소득수준 등 매출액의 변동에 영향을 줄 수 있는 다른 많은 변수를 포함시키더라도 매출액 변동을 100% 설명하는 것은 불가능하다고 할 수 있다. 이와 같이 설명할 수 없는 반응변수의 변동이 항상 존재하는 경우에는 반응변수와 설명변수의 관계를 다음과 같이 오차항 \\(\\varepsilon\\)를 포함시켜서 표현할 수 있다. \\[\\begin{equation} Y = f(X) + \\varepsilon \\tag{1.1} \\end{equation}\\] 오차항 \\(\\varepsilon\\)는 모형 \\(f(X)\\)로 설명되지 않는 반응변수의 변동을 나타낸다. 모형 \\(f(X)\\)에 대해서는 직선 혹은 곡선 등의 함수형태를 가정하는 방법이 있다. 반응변수와 설명변수의 관계가 설정된 함수형태를 항상 따른다는 것은 매우 강한 제약 조건이 될 수 있으나, 반응변수와 설명변수 사이에 존재하는 참 관계를 잘 나타낼 수 있다면 매우 효과적인 분석 모형이 될 것이다. 실제로 참 관계는 매우 복잡한 형태가 될 수 있으며, 대부분의 경우 정확한 모습은 미리 알 수 없다. 만일 참 관계가 그림 1.1와 같다면, 선형식으로 충분히 근사될 수 있을 것이다. 그림 1.1: 복잡한 관계에 대한 선형회귀 근사 이 책에서는 모형 \\(f(X)\\)에 대해서 함수형태를 가정하는 방법만 다룰 예정이다. 함수형태를 가정하기 위한 가장 단순한 방법은 두 변수의 산점도를 작성하는 것이다. 예를 들어, 두 변수의 산점도가 그림 1.2와 같다면 함수 \\(f\\)를 직선 형태로 가정할 수 있을 것이고, 그림 1.3와 같다면, 2차 함수 관계로 가정할 수 있을 것이다. 그림 1.2: 직선 관계 함수 그림 1.3: 이차 관계 함수 모형 \\(f(X)\\)에 대해 특별한 함수 형태를 가정하지 않는 방법도 있다. 국소회귀(local regression)와 같은 비모수적 회귀모형(non-parametric regression model)에서 일반적으로 적용되는 방법이다. 이 책에서는 구체적인 내용을 다루지 않고 있다. 1.2 회귀모형의 설정 본 절에서는 반응변수와 설명변수 사이의 관계를 모형화하는 기법인 회귀모형의 설정에 대하여 살펴보겠다. 만일 특정 제품의 매출액과 광고비 지출액의 관계가 그림 1.2와 같다고 하면, 두 변수의 관계는 다음과 같이 표현할 수 있다. \\[\\begin{equation} Y = \\beta_{0} + \\beta_{1}X + \\varepsilon \\tag{1.2} \\end{equation}\\] 반응변수와 설명변수에 대한 회귀모형을 식 (1.2)와 같이 설정하면, 회귀직선은 두 변수 사이의 참 관계(true relation)에 대한 근사(approximation)를 의미한다. 식 (1.2)에서 \\(\\beta_{0}\\)와 \\(\\beta_{1}\\)은 두 변수의 관계를 규정하는 ’모집단 회귀직선’의 Y축 절편과 직선의 기울기를 각각 나타내는 있는 모수(parameter)이며, 회귀계수(regression coefficient)라고 불린다. 그림 1.2에서 자료들은 직선 위에 위치하지 않고 있는데, 이와 같은 반응변수의 관측값과 직선(\\(\\beta_{0}+\\beta_{1}X\\))의 차이를 나타내기 위하여 오차항 \\(\\varepsilon\\)이 포함되었다. 오차항은 광고비 지출 이외의 다른 변수들의 영향이나 측정 오차 등을 포함하는 통계적 오차가 된다. 식 (1.2)를 단순선형회귀모형(simple linear regression model)이라고 부른다. 여기에서 ’단순’은 모형에 설명변수가 하나만 있다는 것을 의미하고, ’선형’은 모형에 포함된 모수 사이의 관계가 선형임을 의미한다. 설명변수의 개수를 \\(k\\)로 늘린 회귀모형은 다음과 같이 설정할 수 있다. \\[\\begin{equation} Y = \\beta_{0} + \\beta_{1}X_{1} + \\cdots + \\beta_{k}X_{k} + \\varepsilon \\tag{1.3} \\end{equation}\\] 식 (1.3)을 다중선형회귀모형(multiple linear regression model)이라고 부른다. 여기에서 ’다중’은 모형에 포함된 설명변수의 개수가 두 개 이상인 경우를 의미한다. 회귀분석의 중요한 목적 중 하나는 회귀모형에 포함된 모수를 추정하는 것이다. 이러한 절차를 모형의 적합(fitting)이라고 하며, 2장에서는 회귀분석에서 가장 많이 사용되는 추정 방법인 최고제곱추정 방법이 소개될 것이다. 예를 들어 그림 1.2에 주어진 자료를 이용해서 구한 최소제곱추정에 의한 회귀직선식은 다음과 같이 주어진다. \\[\\begin{equation} \\hat{Y}=2.1 + 4.9X \\end{equation}\\] 여기에서 \\(\\hat{Y}\\)은 광고비 지출액이 \\(X\\)일 때 대응되는 평균 매출액의 추정값이 된다. 일반적으로 추정된 회귀식은 설명변수가 관측된 범위 내에서만 적용하는 것이 바람직하다. 예를 들면, 그림 1.4에서 두 변수 \\(Y\\)와 \\(X\\)에 대한 자료가 \\(x_{1} \\leq X \\leq x_{2}\\)의 범위에서 수집되었다고 하자. 이 범위에서 참 관계는 직선으로 근사될 수 있을 것이다. 그러나 \\(X \\geq x_{2}\\)의 범위에서 반응변수의 값을 선형 근사 관계를 근거로 예측하고자 한다면 심각한 신뢰성 문제가 발생하게 된다. 설명변수가 관측된 범위를 벗어난 구역에 대한 예측은 가능한 시도하지 않는 것이 좋겠지만, 시도를 해야만 하는 상황이라면 매우 조심해서 예측 결과를 적용해야 할 것이다. 그림 1.4: 회귀모형의 유효성 문제 1.3 회귀모형의 사용 회귀모형은 다음과 같은 목적으로 사용될 수 있다. 자료의 기술(Data description) 자료들의 특징이나 변수들 사이의 관계 등을 명확하게 밝히는 것이 분석 목적이 되는 경우가 있다. 이런 경우에는 두 변수 사이의 함수형태를 가정하지 않는 비모수적 회귀모형이 효과적인 분석 방식이 될 수 있다. 그림 1.5는 2014년 호주 빅토리아주에서 측정된 일일 최고 기온과 전기 사용량의 산점도와 두 변수에 대한 비모수적 회귀모형의 적합 결과를 나타낸 그래프이다. 명확한 2차 곡선의 관계가 잘 드러난 예제이다. 그림 1.5: 자료의 기술 목적으로 사용된 회귀모형의 예 예측(Prediction) 새롭게 관측되는 자료에 대한 가장 정확한 예측값을 생성하는 것이 분석의 목적이 되는 경우가 많이 있다. 예를 들어 특정 제품의 매출액을 정확하게 예측하는 것은 모든 기업의 중요한 업무라 하겠다. 만일 반응변수인 매출액과 광고비, 가격수준, 기술수준, 디자인 선호수준, 소득수준 등의 설명변수 사이의 참 관계가 식 (1.2) 혹은 식 (1.3)의 모형으로 잘 설명이 된다면, 회귀모형은 매우 효과적인 예측모형으로 사용될 수 있을 것이다. 이 책에서는 예측모형으로써 회귀모형의 특성 등에 대하여 상세하게 살펴볼 것이다. 1.4 R의 역할 최종 회귀모형을 얻기 위해서는 많은 분석 단계를 거쳐야 한다. 자료의 특성을 잘 보여줄 수 있는 그래프 작성이 가능해야 하며, 반복적인 처리를 통해서 적합 과정의 문제를 발견할 수 있어야 하고, 효과적인 예측을 실시할 수 있어야 한다. 따라서 성공적인 분석을 실시하기 위해서는 고급통계분석에 가장 적절한 프로그래밍 언어를 선택해야 한다. 이 책에서는 R을 사용하여 회귀분석의 모든 과정을 자세하게 소개할 것이다. 기본적인 R 사용법이나 패키지 dplyr과 ggplot2에 대해서는 책을 읽는 분들이 어느 정도 익숙하다는 가정을 하고 있다. 또한 책에 제공된 R code에는 프롬프트(&gt; 또는 +)를 제거하였고, console 창에 출력되는 결과물은 ##으로 시작되도록 하였다. 이 책을 작성할 때의 R 세션 정보는 다음과 같다. sessionInfo() ## R version 4.3.1 (2023-06-16 ucrt) ## Platform: x86_64-w64-mingw32/x64 (64-bit) ## Running under: Windows 11 x64 (build 22621) ## ## Matrix products: default ## ## ## locale: ## [1] LC_COLLATE=Korean_Korea.utf8 LC_CTYPE=Korean_Korea.utf8 ## [3] LC_MONETARY=Korean_Korea.utf8 LC_NUMERIC=C ## [5] LC_TIME=Korean_Korea.utf8 ## ## time zone: Asia/Seoul ## tzcode source: internal ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] expsmooth_2.3 fma_2.5 forecast_8.21 fpp2_2.5 ## [5] lubridate_1.9.2 forcats_1.0.0 stringr_1.5.0 dplyr_1.1.2 ## [9] purrr_1.0.1 readr_2.1.4 tidyr_1.3.0 tibble_3.2.1 ## [13] ggplot2_3.4.3 tidyverse_2.0.0 ## ## loaded via a namespace (and not attached): ## [1] gtable_0.3.3 xfun_0.39 bslib_0.5.1 lattice_0.21-8 ## [5] tzdb_0.4.0 quadprog_1.5-8 vctrs_0.6.3 tools_4.3.1 ## [9] generics_0.1.3 curl_5.0.2 parallel_4.3.1 fansi_1.0.4 ## [13] highr_0.10 xts_0.13.1 pkgconfig_2.0.3 Matrix_1.6-1 ## [17] lifecycle_1.0.3 compiler_4.3.1 farver_2.1.1 munsell_0.5.0 ## [21] htmltools_0.5.5 sass_0.4.7 yaml_2.3.7 pillar_1.9.0 ## [25] crayon_1.5.2 jquerylib_0.1.4 cachem_1.0.8 nlme_3.1-163 ## [29] fracdiff_1.5-2 tidyselect_1.2.0 digest_0.6.33 stringi_1.7.12 ## [33] bookdown_0.35 splines_4.3.1 labeling_0.4.2 tseries_0.10-54 ## [37] fastmap_1.1.1 grid_4.3.1 colorspace_2.1-0 cli_3.6.1 ## [41] magrittr_2.0.3 utf8_1.2.3 withr_2.5.0 scales_1.2.1 ## [45] timechange_0.2.0 TTR_0.24.3 rmarkdown_2.24 quantmod_0.4.24 ## [49] nnet_7.3-19 timeDate_4022.108 zoo_1.8-12 hms_1.1.3 ## [53] urca_1.3-3 evaluate_0.21 knitr_1.43 lmtest_0.9-40 ## [57] mgcv_1.9-0 rlang_1.1.1 Rcpp_1.0.11 glue_1.6.2 ## [61] rstudioapi_0.15.0 jsonlite_1.8.7 R6_2.5.1 "],["simple-reg.html", "2 장 단순회귀모형 2.1 단순회귀모형의 설정 2.2 회귀계수의 최소제곱추정", " 2 장 단순회귀모형 회귀모형의 가장 기본적인 형태로써 한 개의 설명변수로 반응변수의 변동을 설명하려는 단순회귀모형에 대해서 살펴보도록 하자. 특히 두 변수의 관계가 직선인 경우에 대해서만 다루겠다. 2.1 단순회귀모형의 설정 설명변수가 하나이고, 반응변수와의 관계가 직선인 경우에 회귀모형은 다음과 같이 설정된다. \\[\\begin{equation} Y_{i} = \\beta_{0} + \\beta_{1}X_{i} + \\varepsilon_{i}, ~~i=1,2,\\ldots,n \\tag{2.1} \\end{equation}\\] 여기에서 \\(Y_{i}\\) 는 반응변수의 \\(i\\) 번째 값, \\(X_{i}\\) 는 설명변수의 \\(i\\) 번째 값을 표시한다. 절편 \\(\\beta_{0}\\) 와 \\(\\beta_{1}\\) 은 모수(parameter)이며, 따라서 알려지지 않은 상수(constant)이다. 오차항 \\(\\varepsilon_{i}\\) 는 반응변수의 변동 중 설명변수로 설명할 수 없는 부분을 나타내는 확률변수인데, \\(n\\) 개의 오차항이 모두 평균이 0, 분산은 \\(\\sigma^{2}\\) 이며, 서로 독립이라고 가정한다. 또한 설명변수의 값 \\(X_{i}\\) 는 분석자에 의해서 값이 통제될 수 있는 변량으로써 확률변수가 아닌 상수라고 가정한다. 이러한 가정에서 단순회귀모형의 특성을 다음과 같이 유도할 수 있다. \\(Y_{i}\\) 는 상수인 \\(\\beta_{0}+\\beta_{1}X_{i}\\)와 확률변수인 \\(\\varepsilon_{i}\\)의 합으로 구성되어 있다. 따라서 \\(Y_{i}\\)는 확률변수이다. 설명변수의 값이 \\(X_{i}\\)로 주어졌을 때, 확률변수 \\(Y_{i}\\)의 평균은 다음과 같다. \\[\\begin{align*} E(Y_{i}|X_{i}) &amp; = E(\\beta_{0} + \\beta_{1}X_{i} + \\varepsilon_{i}) \\\\ &amp; = \\beta_{0} + \\beta_{1}X_{i} + E(\\varepsilon_{i}) \\\\ &amp; = \\beta_{0} + \\beta_{1}X_{i} \\end{align*}\\] 위 수식에서 \\(\\beta_{0}+\\beta_{1}X_{i}\\)는 상수이기 때문에 기대값은 동일한 값이 되고, \\(E(\\varepsilon_{i})=0\\) 은 가정에 의한 결과이다. 설명변수의 값이 \\(X_{i}\\)로 주어졌을 때, 확률변수 \\(Y_{i}\\)의 분산은 다음과 같다. \\[\\begin{align*} Var(Y_{i}|X_{i}) &amp; = Var(\\beta_{0} + \\beta_{1}X_{i} + \\varepsilon_{i}) \\\\ &amp; = Var(\\beta_{0} + \\beta_{1}X_{i}) + Var(\\varepsilon_{i}) \\\\ &amp; = \\sigma^{2} \\end{align*}\\] 위 수식에서 \\(\\beta_{0}+\\beta_{1}X_{i}\\)는 상수이기 때문에 분산은 0이고 되고, \\(Var(\\varepsilon_{i}) = \\sigma^{2}\\) 는 가정에 의한 결과이다. 위 결과를 종합하면 설명변수의 값이 \\(X_{i}\\)로 주어졌을 때, 확률변수 \\(Y_{i}\\)는 평균이 \\(\\beta_{0}+\\beta_{1}X_{i}\\)이고 분산이 \\(\\sigma^{2}\\)이 된다. 즉, 반응변수의 평균은 설명변수의 값에 따라 절편이 \\(\\beta_{0}\\)이고 기울기가 \\(\\beta_{1}\\)인 직선을 따라 움직인다는 것을 알 수 있는데, 이 직선을 ’모집단 회귀직선’이라고 한다. 또한 반응변수의 평균은 설명변수의 값에 따라 변하지만, 분산은 항상 일정한 값을 갖는다는 것을 알 수 있다. \\(n\\)개의 오차항 \\(\\varepsilon_{1}, \\ldots, \\varepsilon_{n}\\)들이 서로 독립이라고 가정했기 때문에 반응변수도 서로 독립이 된다. 따라서 \\(Y_{i}\\)와 \\(Y_{j}\\)는 \\(i \\ne j\\) 라면, 서로 독립이기 때문에 두 변수의 공분산은 \\(Cov(Y_{i}, Y_{j})=0\\) 이 된다. 두 확률변수 \\(X\\)와 \\(Y\\)의 공분산 \\(Cov(X,Y)\\)는 다음과 같이 정의된다. \\[\\begin{align} Cov(X,Y) &amp; = E\\left((X-E(X))(Y-E(Y)) \\right) \\\\ &amp; = E(XY) - E(X)E(Y) \\tag{2.2} \\end{align}\\] 만일 확률변수 \\(X\\)와 \\(Y\\)가 서로 독립이면, \\(E(XY)=E(X)E(Y)\\)의 관계가 성립한다. 따라서 서로 독립인 두 확률변수의 공분산은 식 (2.2)에 의해서 0이 됨을 알 수 있다. 공분산 \\(Cov(X,Y)\\) 는 변수 \\(X\\)와 \\(Y\\) 사이에 존재하는 선형 관련성을 측정하는 통계량이다. 식 (2.2)에서 볼 수 있듯이 공분산은 변수 \\((X-E(X))(Y-E(Y)\\)의 평균값을 나타낸다. 만일 \\((X,Y)\\)의 자료 중 \\(X-E(X)&gt;0\\)이고 \\(Y-E(Y)&gt;0\\)을 만족하거나 \\(X-E(X)&lt;0\\)이고 \\(Y-E(Y)&lt;0\\)인 조건을 만족하는 자료가 많게 되면 변수 \\((X-E(X))(Y-E(Y)\\)의 값은 대부분 양수의 값이 되며, 따라서 변수 \\((X-E(X))(Y-E(Y)\\)의 평균값인 두 변수의 공분산은 0보다 큰 값을 갖게 된다. 하지만 \\((X,Y)\\)의 자료 중 \\(X-E(X)\\)와 \\(Y-E(Y)\\)의 부호가 서로 반대가 되는 자료가 많게 되면 변수 \\((X-E(X))(Y-E(Y)\\)의 값은 대부분 음수의 값이 되며, 따라서 변수 \\((X-E(X))(Y-E(Y)\\)의 평균값인 두 변수의 공분산은 0보다 작은 값을 갖게 된다. 그런데 \\((X,Y)\\)의 자료 중 \\(X-E(X)\\)와 \\(Y-E(Y)\\)의 부호가 같은 자료들이 많다는 것은 그림 2.1에서 1구역과 3구역에 대부분의 자료가 있다는 것을 의미하고 있기 때문에 한 변수의 값이 증가하거나 감소하면 다른 변수의 값도 함께 증가하거나 감소하는 ’양의 관계’에 있다는 것을 알 수 있다. 또한 \\((X,Y)\\)의 자료 중 \\(X-E(X)\\)와 \\(Y-E(Y)\\)의 부호가 반대인 자료들이 많다는 것은 그림 2.1에서 2구역과 4구역에 대부분의 자료가 있다는 것을 의미하는 것이고, 따라서 한 변수의 값이 증가하거나 감소하면 다른 변수의 값은 정반대의 방향으로 움직이는 ’음의 관계’에 있다는 것을 알 수 있다. 이러한 관련성으로 두 변수의 공분산이 큰 양수 값이면 두 변수의 관계는 강한 양의 관계가 있음을 알 수 있으며, 큰 음수의 값을 취하고 있으면 강한 음의 관계가 있음을 알 수 있다. 그러나 공분산의 값은 변수가 취하는 값 자체의 절대적 크기에도 영향을 받고 있기 때문에 스케일이 다른 자료에 대한 비교는 의미가 없게 된다. 이 문제는 공분산을 두 변수의 표준편차를 나누는 것으로 해결될 수 있으며, 이것이 상관계수가 된다. 그림 2.1: 두 변수 X와 Y의 공분산 구성요소 2.2 회귀계수의 최소제곱추정 식 (2.1)을 이용해서 \\(Y\\) 의 변동을 설명하고 예측하려면, 값이 알려져 있지 않는 모수 \\(\\beta_{0}\\) 와 \\(\\beta_{1}\\) 을 추정해야 한다. 두 변수 \\(Y\\) 와 \\(X\\) 에 대해 관측된 \\(n\\) 개의 자료를 \\((y_{1},x_{1})\\), \\((y_{2}, x_{2})\\), \\(\\ldots\\), \\((y_{n}, x_{n})\\) 이라고 하자. 두 모수 \\(\\beta_{0}\\) 와 \\(\\beta_{1}\\) 의 추정은 \\(n\\) 개의 자료를 가장 잘 설명할 수 있는 직선을 구하는 과정이라고 할 수 있는데, ’자료를 가장 잘 설명하는 직선’이란 자료와 직선 사이에 간격이 가장 작은 직선이라고 볼 수 있다. 최소제곱추정법은 이런 개념을 활용한 추정법이며, 선형회귀모형에서 가장 널리 사용되는 회귀계수의 추정방법이다. 2.2.1 모수 \\(\\beta_{0}\\)와 \\(\\beta_{1}\\)의 추정 두 모수의 추정값을 \\(\\hat{\\beta}_{0}\\) 과 \\(\\hat{\\beta}_{1}\\) 라고 하면, \\(X\\) 변수의 \\(i\\) 번째 관찰값에 대한 \\(Y\\) 변수의 \\(i\\) 번째 예측값은 \\(\\hat{y}_{i} = \\hat{\\beta}_{0} + \\hat{\\beta}_{1}x_{i}\\) 가 된다. \\(Y\\) 변수의 관찰값인 \\(y_{i}\\) 와 예측값인 \\(\\hat{y}_{i}\\) 의 차이인 \\(y_{i}-\\hat{y}_{i}\\) 는 자료와 회귀직선 사이의 거리가 되는데, 이것을 잔차(residual)라고 하며, \\(e_{i}\\) 로 표시한다. 따라서 \\(\\hat{\\beta}_{0}\\) 과 \\(\\hat{\\beta}_{1}\\) 은 다음에 주어지는 잔차의 제곱합(Residual sum of squares; RSS)을 최소화시키도록 구해야 한다. \\[\\begin{equation} RSS = \\sum_{i=1}^{n} \\left( y_{i}-\\hat{\\beta}_{0}-\\hat{\\beta}_{1}x_{i} \\right)^{2} \\tag{2.3} \\end{equation}\\] 식 (2.3)의 RSS를 최소화시키는 추정값 \\(\\hat{\\beta}_{0}\\) 과 \\(\\hat{\\beta}_{1}\\) 을 구하기 위해서, RSS를 \\(\\hat{\\beta}_{0}\\) 과 \\(\\hat{\\beta}_{1}\\) 에 대하여 각각 편미분을 실시해서 얻은 두 개의 방정식은 다음과 같다. \\[\\begin{align} \\frac{\\partial RSS}{\\partial \\hat{\\beta}_{0}} &amp; = -2 \\sum_{i=1}^{n}(y_{i}-\\hat{\\beta}_{0}-\\hat{\\beta}_{1}x_{i}) = 0\\\\ \\frac{\\partial RSS}{\\partial \\hat{\\beta}_{1}} &amp; = -2 \\sum_{i=1}^{n}x_{i}(y_{i}-\\hat{\\beta}_{0}-\\hat{\\beta}_{1}x_{i}) = 0 \\tag{2.4} \\end{align}\\] 식 (2.4)을 정리하면 다음과 같다. \\[\\begin{align} \\sum_{i=1}^{n}y_{i} &amp; = n \\hat{\\beta}_{0} + \\hat{\\beta}_{1} \\sum_{i=1}^{n}x_{i} \\\\ \\sum_{i=1}^{n}x_{i}y_{i} &amp; = \\hat{\\beta}_{0}\\sum_{i=1}^{n}x_{i} + \\hat{\\beta}_{1}\\sum_{i=1}^{n}x_{i}^{2} \\tag{2.5} \\end{align}\\] 식 (2.5)를 \\(\\hat{\\beta}_{0}\\) 과 \\(\\hat{\\beta}_{1}\\) 에 대하여 정리하면 각각 다음의 결과를 얻게 된다. \\[\\begin{align} \\hat{\\beta}_{1} &amp;= \\frac{\\sum_{i=1}^{n}(x_{i}-\\overline{x})(y_{i}-\\overline{y})}{\\sum_{i=1}^{n}(x_{i}-\\overline{x})^{2}} \\\\ \\hat{\\beta}_{0} &amp;= \\overline{y}-\\hat{\\beta}_{1}\\overline{x} \\tag{2.6} \\end{align}\\] 단, \\(\\overline{y}\\) 와 \\(\\overline{x}\\) 는 표본평균이다. 추정된 회귀직선의 기울기인 \\(\\hat{\\beta}_{1}\\)의 의미는 설명변수를 한 단위 증가시켰을 때 반응변수의 평균 변화량의 추정값이 되어서, \\(\\hat{\\beta}_{1}&gt;0\\)이면 설명변수 값의 증가가 반응변수 값의 증가로 연결되는 관계를 의미하고, 반면에 \\(\\hat{\\beta}_{1}&lt;0\\)이면 설명변수 값의 증가가 반응변수 값의 감소로 연결되는 관계를 의미한다. 절편인 \\(\\hat{\\beta}_{0}\\) 은 설명변수의 값이 0일 때, 반응변수의 평균값의 추정값이 되는데, 만일 설명변수의 값 범위에 0이 포함되지 않는다면 특별한 의미를 부여하기는 어렵다. 식 (2.1)에 포함된 오차항 \\(\\varepsilon_{i}\\)는 자료를 통해서 관측될 수 없는 변량이다. 하지만 회귀모형에서는 오차항에 대해 몇 가지 가정을 하고 있으며, 이 가정이 만족되지 않는 자료를 대상으로 식 (2.1)의 회귀모형을 적용시켜 분석하게 되면, 그 결과에 심각한 문제가 발생할 수 있다. 따라서 가정 만족 여부를 확인하는 것은 매우 중요한 분석 과정이 되는데, 이 경우 오차항 대신 사용할 수 있는 것이 잔차이다. 잔차분석에 대해서는 5장에서 살펴보겠다. \\(\\bullet\\) 예제 2.1: 모집단 회귀직선과 추정된 회귀직선 모집단 회귀직선과 오차항의 분포는 일반적으로 알려져 있지 않지만, 회귀모형의 의미를 살펴보기 위해서 \\(E(Y|X)=5+2X\\) 라고 가정하고, 오차항 \\(\\varepsilon\\)은 평균이 0이고 분산이 1인 표준정규분포라고 가정하자. 설명변수의 값이 1, 3, 2, 7, 12, 6, 1, 3, 6, 6, 7로 주어졌을 때, 표준정규분포에서 발생시킨 오차값을 추가해서 반응변수의 값을 생성해 보자. 단순선형회귀모형을 자료에 적합시켜서 절편과 기울기를 추정하고 모집단 회귀직선과 비교해 보자. 주어진 설명변수의 값에 대해 정규 난수를 추가한 반응변수 값을 생성해서 데이터 프레임으로 만들어 보자. 표준정규분포에서 난수 생성은 함수 rnorm()으로 수행할 수 있다. library(tidyverse) set.seed(12) df2.1 &lt;- tibble(x = c(1, 3, 2, 7, 12, 6, 1, 3, 6, 6, 7), y = 5 + 2*x + rnorm(length(x)) ) 생성된 모의자료는 다음과 같다. df2.1 ## # A tibble: 11 × 2 ## x y ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1 5.52 ## 2 3 12.6 ## 3 2 8.04 ## 4 7 18.1 ## 5 12 27.0 ## 6 6 16.7 ## 7 1 6.68 ## 8 3 10.4 ## 9 6 16.9 ## 10 6 17.4 ## 11 7 18.2 선형화귀모형의 적합은 함수 lm()으로 할 수 있으며, 일반적인 사용법은 lm(formula, data, ...)이다. formula는 설정된 회귀모형을 나타내는 R 모형 공식으로써, 단순회귀모형의 경우에는 y ~ x와 같이 물결표(~)의 왼쪽에는 반응변수, 오른쪽에는 설명변수를 두면 된다. R 모형 공식에 대해서는 다중회귀모형에서 더 자세하게 살펴보겠다. data는 회귀분석에 사용될 데이터 프레임을 지정하는 것으로써, 이 예제에서는 위에서 생성한 데이터 프레임 df2.1를 지정하면 된다. 모의자료가 있는 데이터 프레임 df2.1를 대상으로 단순회귀모형을 함수 lm()으로 적합시켜보자. 적합 결과는 \\(\\hat{y} = 4.94 + 1.911x\\) 임을 알 수 있다. fit2.1 &lt;- lm(y ~ x, data = df2.1) fit2.1 ## ## Call: ## lm(formula = y ~ x, data = df2.1) ## ## Coefficients: ## (Intercept) x ## 4.940 1.911 함수 lm()으로 생성된 객체 fit2.1을 단순하게 출력시키면 추정된 회귀계수만 나타나지만, 사실 객체 fit2.1은 다음과 같이 많은 양의 정보가 담겨 있는 리스트 객체이다. names(fit2.1) ## [1] &quot;coefficients&quot; &quot;residuals&quot; &quot;effects&quot; &quot;rank&quot; ## [5] &quot;fitted.values&quot; &quot;assign&quot; &quot;qr&quot; &quot;df.residual&quot; ## [9] &quot;xlevels&quot; &quot;call&quot; &quot;terms&quot; &quot;model&quot; 사용자마다 필요한 정보가 서로 다를 수 있기 때문에 SAS나 SPSS에서와 같이 모든 결과물을 한 번에 출력하는 것은 좋은 방법이 아닐 수 있다. 객체 fit2.1에 담겨 있는 필요한 정보를 획득하기 위해서는 해당하는 함수를 사용해야 하며, 앞으로 차근차근 살펴보겠다. 모집단 회귀직선 및 생성된 모의자료, 그리고 추정된 회귀직선을 함께 나타낸 그래프가 그림 2.2이다. 추정된 회귀직선은 모집단 회귀직선과 매우 비숫하지만 완벽하게 일치하지 않음을 알 수 있다. 그림 2.2: 예제 2.1에서 사용된 모의자료와 회귀직선 \\(\\bullet\\) 예제 2.2: 매출액에 대한 광고효과 분석 피자 전문 체인점 영업부서에서는 매출액에 대한 광고효과를 분석하기 위하여 유사한 인구분포를 갖는 20개 판매지역의 매출액 규모와 광고비 지출에 대한 자료를 수집하였다. 수집된 자료는 파일 ex2-2.csv에 입력되었고, 자료의 단위는 100만원이다. 매출액 규모와 광고비 지출 사이의 산점도를 작성하고, 두 변수 사이의 관계를 살펴보자. 최소제곱법에 의한 단순회귀직선을 추정하고, 추정된 \\(\\hat{\\beta}_{1}\\)의 의미를 해석해 보자. 자료가 콤마로 구분된 CSV 파일을 함수 readr::read_csv()로 불러와서 두 변수의 산점도를 작성해 보자. df2.2 &lt;- readr::read_csv(&quot;Data/ex2-2.csv&quot;) df2.2 ## # A tibble: 20 × 2 ## sales advertisement ## &lt;dbl&gt; &lt;dbl&gt; ## 1 425 23 ## 2 370 21 ## 3 200 16 ## 4 580 34 ## 5 620 32 ## 6 650 36 ## 7 700 40 ## 8 490 37 ## 9 610 35 ## 10 290 20 ## 11 320 20 ## 12 350 21 ## 13 400 23 ## 14 517 21 ## 15 545 30 ## 16 590 32 ## 17 711 39 ## 18 650 37 ## 19 740 41 ## 20 660 38 ggplot(df2.2, aes(x = advertisement, y = sales)) + geom_point(size = 2) + geom_smooth(se = FALSE, aes(color = &quot;비모수적 회귀곡선&quot;)) + geom_smooth(method = &quot;lm&quot;, se = FALSE, aes(color = &quot;회귀직선&quot;)) + labs(color = NULL) 그림 2.3: 예제 2.2 자료의 산점도와 비모수적 회귀곡선 비모수적 회귀곡선은 두 변수의 관계를 가장 잘 나타내는 곡선을 추정하는 기능을 가지고 있다. 그림 2.3에 작성된 비모수적 회귀곡선은 대체로 직선의 형태를 취하고 있음을 알 수 있으며, 함께 표시된 회귀직선과 큰 차이가 없는 것을 알 수 있다. 이것으로 두 변수의 관계를 직선으로 설정하는 데에 큰 무리가 없음을 알 수 있다. 함수 lm()으로 단순회귀직선을 추정해 보자. fit2.2 &lt;- lm(sales ~ advertisement, data = df2.2) fit2.2 ## ## Call: ## lm(formula = sales ~ advertisement, data = df2.2) ## ## Coefficients: ## (Intercept) advertisement ## -6.944 17.713 적합 결과는 \\(\\hat{y} = -6.994 + 17.713x\\) 임을 알 수 있다. 추정된 직선의 기울기 \\(\\hat{\\beta}_{1}=17.713\\) 의 의미는 광고비 지출을 한 단위인 100만원 증가시키면 평균 매출액의 규모가 17.713백만원 증가한다는 것이 된다. 절편 \\(\\hat{\\beta}_{0}=-6.994\\) 의 의미는 광고비 지출이 \\(0\\) 일 때 평균 매출액은 -6.994백만원이라는 것이 된다. 즉, 광고를 하지 않으면 적자를 본다는 것인데, 이러한 해석은 조사된 광고비 자료의 범위에 \\(0\\) 이 포함되어 있지 않기 때문에 적절하지 않다고 하겠다. 2.2.2 최소제곱추정량의 특성 식 (2.1)에서 설정된 단순회귀모형에서 모수 \\(\\beta_{0}\\)와 \\(\\beta_{1}\\)의 최소제곱추정량인 \\(\\hat{\\beta}_{0}\\)과 \\(\\hat{\\beta}_{1}\\)은 몇 가지 중요한 통계적 특성을 갖는다. 첫 번째 특성은 식 (2.6)의 \\(\\hat{\\beta}_{0}\\)과 \\(\\hat{\\beta}_{1}\\)은 반응변수 \\(Y_{i}\\)의 선형결합으로 표시된다는 것이다. 먼저 \\(\\hat{\\beta}_{1}\\)의 경우를 살펴보자. \\[\\begin{align} \\hat{\\beta}_{1} &amp; = \\frac{\\sum_{i=1}^{n}(X_{i}-\\overline{X})(Y_{i}-\\overline{Y})}{\\sum_{i=1}^{n}(X_{i}-\\overline{X})^{2}} \\\\ &amp; = \\frac{\\sum_{i=1}^{n}(X_{i}-\\overline{X})Y_{i}-\\sum_{i=1}^{n}(X_{i}-\\overline{X})\\overline{Y}}{\\sum_{i=1}^{n}(X_{i}-\\overline{X})^{2}} \\\\ &amp; = \\frac{\\sum_{i=1}^{n}(X_{i}-\\overline{X})Y_{i}}{\\sum_{i=1}^{n}(X_{i}-\\overline{X})^{2}} \\\\ &amp; = \\sum_{i=1}^{n}\\left(\\frac{X_{i}-\\overline{X}}{\\sum_{i=1}^{n}(X_{i}-\\overline{X})^{2}}\\right)Y_{i} \\\\ &amp; = \\sum_{i=1}^{n}c_{i}Y_{i} \\tag{2.7} \\end{align}\\] 단, \\(c_{i} = (X_{i}-\\overline{X})/\\sum(X_{i}-\\overline{X})^{2}\\). \\(\\hat{\\beta}_{0}\\)의 경우에는 \\(\\overline{Y}-\\hat{\\beta}_{1}\\overline{X}\\)의 표현식에서 \\(\\hat{\\beta}_{1}\\)이 \\(Y_{i}\\)의 선형결합이기 때문에 자연스럽게 \\(Y_{i}\\)의 선형결합으로 표시됨을 알 수 있다. 두 번째 특성은 최소제곱추정량이 불편추정량(unbiased estimator)이라는 것이다. 불편추정량이란 추정량의 기대값이 추정하려는 모수와 일치하는 추정량을 의미한다. 먼저 \\(\\hat{\\beta}_{1}\\)의 기대값을 구해보자. \\[\\begin{align} E\\left(\\hat{\\beta}_{1}\\right) &amp; = E\\left(\\sum_{i=1}^{n}c_{i}Y_{i}\\right) \\\\ &amp; = \\sum_{i=1}^{n}c_{i}E(Y_{i}) \\\\ &amp; = \\sum_{i=1}^{n}c_{i}E(\\beta_{0}+\\beta_{i}X_{i}) \\\\ &amp; = \\beta_{0}\\sum_{i=1}^{n}c_{i}+\\beta_{1}\\sum_{i=1}^{n}c_{i}X_{i} \\tag{2.8} \\end{align}\\] \\(\\sum c_{i}\\)의 값은 다음과 같이 구할 수 있다. \\[\\begin{equation} \\sum_{i=1}^{n} c_{i} = \\frac{\\sum_{i=1}^{n}\\left(X_{i}-\\overline{X}\\right)}{\\sum_{i=1}^{n}\\left(X_{i}-\\overline{X}\\right)^{2}} = 0 \\tag{2.9} \\end{equation}\\] 또한 \\(\\sum c_{i}X_{i}\\)의 값은 다음과 같이 구할 수 있다. \\[\\begin{align} \\sum_{i=1}^{n}c_{i}X_{i} &amp; = \\frac{\\sum_{i=1}^{n}\\left(X_{i}-\\overline{X}\\right)X_{i}}{\\sum_{i=1}^{n}\\left(X_{i}-\\overline{X}\\right)^{2}} \\\\ &amp; = \\frac{\\sum_{i=1}^{n}\\left(X_{i}-\\overline{X}\\right)\\left(X_{i}-\\overline{X}\\right)}{\\sum_{i=1}^{n}\\left(X_{i}-\\overline{X}\\right)^{2}} \\\\ &amp; = \\frac{\\sum_{i=1}^{n}\\left(X_{i}-\\overline{X}\\right)^{2}}{\\sum_{i=1}^{n}\\left(X_{i}-\\overline{X}\\right)^{2}} \\\\ &amp; = 1 \\tag{2.10} \\end{align}\\] 식 (2.8)의 마지막 식에서 식 (2.9)와 식 (2.10)의 결과를 적용하면 다음의 결과를 얻게 된다. \\[\\begin{equation} E\\left(\\hat{\\beta}_{1}\\right) = \\beta_{1} \\tag{2.11} \\end{equation}\\] 이제 \\(\\hat{\\beta}_{0}\\)의 기대값을 유도해서 불편추정량임을 보이자. \\[\\begin{align} E\\left(\\hat{\\beta}_{0}\\right) &amp; = E\\left(\\overline{Y}-\\hat{\\beta}_{1}\\overline{X}\\right) \\\\ &amp; = \\frac{1}{n}\\sum_{i=1}^{n}E(Y_{i})-\\overline{X}E\\left(\\hat{\\beta}_{1}\\right) \\\\ &amp; = \\frac{1}{n}\\sum_{i=1}^{n}(\\beta_{0}+\\beta_{1}X_{i}) - \\overline{X}\\beta_{1} \\\\ &amp; = \\beta_{0}+\\beta_{1}\\overline{X}-\\overline{X}\\beta_{1} \\\\ &amp; = \\beta_{0} \\tag{2.12} \\end{align}\\] 불편추정량인 \\(\\hat{\\beta}_{0}\\)과 \\(\\hat{\\beta}_{1}\\)의 분산을 유도해 보자. 식 (2.7)으로 \\(\\hat{\\beta}_{1}\\)은 \\(\\sum c_{i}Y_{i}\\)로 표시할 수 있는데, \\(Y_{i}\\)가 서로 독립이기 때문에 \\(\\hat{\\beta}_{1}\\)의 분산은 다음과 같이 유도할 수 있다. \\[\\begin{align} Var\\left(\\hat{\\beta}_{1}\\right) &amp; = \\sum_{i=1}^{n}c_{i}^{2}Var(Y_{i}) \\\\ &amp; = \\sigma^{2}\\sum_{i=1}^{n}c_{i}^{2} \\\\ &amp; = \\sigma^{2}\\sum_{i=1}^{n}\\left(\\frac{(X_{i}-\\overline{X})}{\\sum_{i=1}^{n}(X_{i}-\\overline{X})^{2}}\\right)^{2} \\\\ &amp; = \\sigma^{2}\\frac{\\sum_{i=1}^{n}(X_{i}-\\overline{X})^{2}}{\\left(\\sum_{i=1}^{n}(X_{i}-\\overline{X})^{2}\\right)^{2}} \\\\ &amp; = \\frac{\\sigma^{2}}{\\sum_{i=1}^{n}(X_{i}-\\overline{X})^{2}} \\tag{2.13} \\end{align}\\] \\(\\hat{\\beta}_{0}\\)의 분산은 다음과 같이 유도할 수 있다. \\[\\begin{align} Var\\left(\\hat{\\beta}_{0}\\right) &amp; = Var\\left(\\overline{Y}-\\hat{\\beta}_{1}\\overline{X}\\right) \\\\ &amp; = Var\\left(\\overline{Y}\\right) + \\overline{X}^{2}Var\\left(\\hat{\\beta}_{1}\\right)-2\\overline{X}Cov\\left(\\overline{Y},\\hat{\\beta}_{1}\\right) \\\\ &amp; = \\frac{\\sigma^{2}}{n} + \\overline{X}^{2}\\frac{\\sigma^{2}}{\\sum_{i=1}^{n}(X_{i}-\\overline{X})^{2}} \\\\ &amp; = \\sigma^{2}\\left(\\frac{1}{n}+\\frac{\\overline{X}^{2}}{\\sum_{i=1}^{n}(X_{i}-\\overline{X})^{2}}\\right) \\tag{2.14} \\end{align}\\] \\(\\overline{Y}\\)와 \\(\\hat{\\beta}_{1}\\)의 공분산이 0임을 보이는 것은 연습문제로 남겨두겠다. 지금까지 살펴본 최소제곱추정량의 특성과 관련된 중요한 결과가 바로 가우스-마코프(Gauss-Markov) 정리이다. 가우스-마코프 정리는 최소제곱추정량으로 회귀계수를 추정해서 사용할 수 있는 근거를 제시하고 있다. 정리 2.1 (Gauss-Markov 정리) 오차항의 평균이 0, 분산이 \\(\\sigma^{2}\\)이며 서로 독립을 가정한 회귀모형에서 최소제곱추정량은 최량선형불편추정량(Best Linear Unbiased Estimator: BLUE)이다. 즉, 최소제곱추정량은 \\(Y_{i}\\)의 선형결합으로 표시되는 모든 불편추정량 중에 최소 분산을 갖는다. \\(\\bullet\\) 최소제곱추정량으로 추정된 회귀직선의 특성 최소제곱추정량으로 추정된 회귀직선은 다음과 같은 몇 가지 유용한 특성을 가지고 있다. 절편을 포함한 회귀모형에서 잔차의 합은 항상 0이다. 이 특성은 식 (2.3)의 RSS를 \\(\\hat{\\beta}_{0}\\)으로 편미분한 식 (2.4)의 첫 번째 방정식에서 바로 확인할 수 있다. \\[\\begin{equation} \\sum_{i=1}^{n}(y_{i}-\\hat{\\beta}_{0}-\\hat{\\beta}_{1}x_{i}) = \\sum_{i=1}^{n}(y_{i}-\\hat{y}_{i}) = \\sum_{i=1}^{n}e_{i} = 0 \\tag{2.15} \\end{equation}\\] 관측값 \\(y_{i}\\)의 합과 추정값 \\(\\hat{y}_{i}\\)의 합은 동일하다. 이 특성은 식 (2.15)에서 확인할 수 있다. 추정된 회귀직선은 항상 표본평균점 \\((\\overline{x}, \\overline{y})\\)을 항상 통과한다. 이 특성은 다음의 수식으로 확인할 수 있다. 마지막 수식에서 \\(x=\\overline{x}\\) 가 되면, \\(\\hat{y}=\\overline{y}\\) 가 되기 때문에 추정된 회귀직선은 \\((\\overline{x}, \\overline{y})\\)을 항상 통과하게 된다. \\[\\begin{align*} \\hat{y} &amp; = \\hat{\\beta}_{0} + \\hat{\\beta}_{1}x \\\\ &amp; = (\\overline{y}-\\hat{\\beta}_{1}\\overline{x}) + \\hat{\\beta}_{1}x \\\\ &amp; = \\overline{y} + \\hat{\\beta}_{1}(x-\\overline{x}) \\end{align*}\\] 잔차의 \\(x_{i}\\)에 대한 가중합은 0이다. 이 특성은 식 (2.3)의 RSS를 \\(\\hat{\\beta}_{1}\\)으로 편미분한 식 (2.4)의 두 번째 방정식에서 바로 확인할 수 있다. \\[\\begin{align*} \\sum_{i=1}^{n}x_{i}(y_{i}-\\hat{\\beta}_{0}-\\hat{\\beta}_{1}x_{i}) &amp; = \\sum_{i=1}^{n}x_{i}y_{i}-\\sum_{i=1}^{n}x_{i}(\\hat{\\beta}_{0}+\\hat{\\beta}_{1}x_{i}) \\\\ &amp; = \\sum_{i=1}^{n}x_{i}y_{i} - \\sum_{i=1}^{n}x_{i}\\hat{y}_{i} \\\\ &amp; = \\sum_{i=1}^{n}x_{i}(y_{i}-\\hat{y}_{i}) \\\\ &amp; = \\sum_{i=1}^{n}x_{i}e_{i} = 0 \\end{align*}\\] 잔차의 \\(\\hat{y}_{i}\\)에 대한 가중합은 0이다. 이 특성은 다음의 수식으로 확인할 수 있다. \\[\\begin{align*} \\sum_{i=1}^{n}\\hat{y}_{i}e_{i} &amp; = \\sum_{i=1}^{n}(\\hat{\\beta}_{0} + \\hat{\\beta}_{1}x_{i})e_{i} \\\\ &amp; = \\hat{\\beta}_{0}\\sum_{i=1}^{n}e_{i} + \\hat{\\beta}_{1}\\sum_{i=1}^{n}x_{i}e_{i} \\\\ &amp; = 0 \\end{align*}\\] 2.2.3 오차분산 \\(\\sigma^{2}\\)의 추정 회귀계수 \\(\\beta_{0}\\)과 \\(\\beta_{1}\\)의 구간추정 및 가설검정을 실시하는 경우와 설명변수의 주어진 값에 대한 반응변수 값의 예측구간 추정 등을 실시하는 경우에는 오차항의 분산인 \\(\\sigma^{2}\\)의 추정값이 반드시 필요하다. 식 (1.1)의 회귀모형에서 회귀모형 \\(f(X)\\)의 실제 형태는 일반적으로 알려져 있지 않으며, 주어진 자료를 근거로 식 (1.2)와 같은 함수형태를 가정하게 된다. 이 때 가정한 함수형태의 적절성 여부와 관계 없이 오차항의 분산을 정확하게 추정할 수 있다면 가장 이상적인 상황이 될 것이다. 그러나 이것은 하나의 \\(X\\) 변수의 값에 대하여 여러 개의 \\(Y\\) 변수의 값이 있는 경우에만 가능한 상황이며, 현실적으로는 접하기 어려운 상황이 된다. 따라서 일반적으로 사용하는 방법은 잔차의 분산으로 오차항의 분산을 추정하는 것이다. 잔차의 평균은 0이기 때문에 잔차의 분산은 잔차제곱합(residual sum of squares; RSS)으로 표현된다. \\[\\begin{equation} RSS = \\sum_{i=1}^{n}\\left(Y_{i}-\\hat{Y}_{i}\\right)^{2} \\tag{2.16} \\end{equation}\\] 회귀모형의 추론 과정에는 잔차제곱합과 같은 형태의 몇 가지 제곱합이 사용된다. 이러한 제곱합은 모두 ’자유도’를 갖게 되는데, 각 제곱합의 자유도는 다음 두 가지 방법 중 적용 가능한 방법으로 구할 수 있다. 변수의 합이 주어진 경우: 예를 들어 \\(X_{1}+X_{2}+X_{3}=0\\) 이라는 조건에서 자유롭게 값을 선택할 수 있는 변수의 개수는 2개가 된다. 그것은 만일 \\(X_{1}\\)과 \\(X_{2}\\)의 값이 선택되면 \\(X_{3}\\)의 값은 자동으로 구해지기 때문이다. 표본분산의 경우 적용되는 제곱합의 형태는 \\(\\sum_{i=1}^{n}(Y_{i}-\\overline{Y})^{2}\\)이 되는데, \\(\\sum_{i=1}^{n}(Y_{i}-\\overline{Y})=0\\) 이라는 조건이 있기 때문에 자유도는 \\(n-1\\)이 된다. 추정량이 포함된 경우: 자유도는 통계학에서 일종의 화폐와 같은 역할을 한다. 수집되는 각 자료마다 하나의 자유도가 추가되는 반면에, 모수에 대한 추정에 이루어질 때마다 하나의 자유도가 차감되는 것이다. 식 (2.16)의 잔차제곱합에서는 \\(n\\)개의 \\(Y_{i}\\)가 수집되지만 \\(\\hat{Y}_{i}\\)를 얻기 위해서는 두 모수 \\(\\beta_{0}\\)와 \\(\\beta_{1}\\)에 대한 추정이 이루어져 2개의 자유도를 잃게 된다. 따라서 잔차제곱합의 자유도는 \\(n-2\\)가 된다. 식 (2.16)의 잔차제곱합 \\(RSS\\)의 기대값은 \\(E(RSS)=(n-2)\\sigma^{2}\\)가 되는데, 이것은 \\(RSS/\\sigma^{2}\\) 가 자유도가 \\(n-2\\) 인 카이제곱 분포를 하고 있으며, 카이제곱 분포를 하는 확률변수의 기대값은 자유도가 된다는 결과에 의해서 \\(E(RSS/\\sigma^{2})=n-2\\) 가 되기 때문이다. 따라서 오차항의 분산인 \\(\\sigma^{2}\\)의 불편추정량은 다음과 같이 정의된다. \\[\\begin{equation} \\hat{\\sigma}^{2} = \\frac{RSS}{n-2} = MSE \\tag{2.17} \\end{equation}\\] \\(\\sigma^{2}\\) 의 추정량인 \\(MSE\\)는 잔차제곱평균이라고 하며, \\(\\sigma\\) 의 추정량인 \\(\\sqrt{MSE}\\)는 회귀 표준오차(standard error of regression)라고 한다. 추정량 \\(MSE\\)는 잔차를 기반으로 오차항의 분산을 추정하는 것이기 때문에 식 (1.2)에서 가정한 함수 형태가 적절해야 하는 것은 필수적이다. 또한 오차항의 가정 사항도 모두 만족되어야 \\(\\sigma^{2}\\)의 좋은 추정량이 될 수 있다. 만일 이러한 가정 사항이 만족되지 않는다면, \\(\\sigma^{2}\\)의 추정량으로서 \\(MSE\\)의 유용성은 매우 떨어진다고 할 수 있다. \\(\\bullet\\) 예제 2.3: 매출액에 대한 광고효과 분석 예제 2.2의 자료 ex2-2.csv에 대하여 다음의 분석을 실시해 보자. 예제 2.2에서 구한 회귀직선으로 주어진 광고비 지출자료에 대한 평균적인 매출액을 추정하고, 잔차를 구하자. \\(\\sigma\\) 의 추정값인 회귀 표준오차를 구해 보자. 예제 2.2에서 이루어진 분석을 다시 실행해 보자. df2.2 &lt;- readr::read_csv(&quot;Data/ex2-2.csv&quot;) fit2.2 &lt;- lm(sales ~ advertisement, data = df2.2) 함수 lm()으로 생성된 리스트 객체 fit2.2에는 \"fitted.values\"와 \"residuals\"라는 이름으로 주어진 설명변수 값에 대한 반응변수의 추정값과 잔차가 입력되어 있다. cbind(df2.2, Yhat = fit2.2$fitted, resid = fit2.2$resid) ## sales advertisement Yhat resid ## 1 425 23 400.4524 24.547619 ## 2 370 21 365.0266 4.973389 ## 3 200 16 276.4622 -76.462185 ## 4 580 34 595.2941 -15.294118 ## 5 620 32 559.8683 60.131653 ## 6 650 36 630.7199 19.280112 ## 7 700 40 701.5714 -1.571429 ## 8 490 37 648.4328 -158.432773 ## 9 610 35 613.0070 -3.007003 ## 10 290 20 347.3137 -57.313725 ## 11 320 20 347.3137 -27.313725 ## 12 350 21 365.0266 -15.026611 ## 13 400 23 400.4524 -0.452381 ## 14 517 21 365.0266 151.973389 ## 15 545 30 524.4426 20.557423 ## 16 590 32 559.8683 30.131653 ## 17 711 39 683.8585 27.141457 ## 18 650 37 648.4328 1.567227 ## 19 740 41 719.2843 20.715686 ## 20 660 38 666.1457 -6.145658 회귀모형의 다양한 추정 결과는 함수 lm()으로 생성된 객체를 함수 summary()에 입력하면 얻을 수 있다. 자세한 사용 방법은 3장에서 살펴볼 것이지만, 여기에서는 함수 summary()의 결과 중 \\(\\sigma\\) 의 추정값만을 출력해 보자. summary(fit2.2)$sigma ## [1] 60.41388 "],["simple-reg-infer.html", "3 장 단순회귀모형의 추론 3.1 회귀계수 \\(\\beta_{1}\\)에 대한 추론 3.2 회귀계수 \\(\\beta_{0}\\)에 대한 추론 3.3 반응변수의 평균, \\(E(Y|X_{o})\\)에 대한 신뢰구간 추정 3.4 반응변수의 개별 관측값 예측 3.5 단순회귀모형에서 두 변수 사이의 연관성 측정: 상관계수", " 3 장 단순회귀모형의 추론 회귀모형의 추론에서 우리가 살펴볼 내용은 회귀계수에 대한 신뢰구간 추정 및 검정, 그리고 설명변수의 값이 주어졌을 때 반응변수의 조건부 평균에 대한 구간추정 등이다. 또한 분산분석 개념을 이용한 회귀모형의 유의성 검정에 대해서도 살펴볼 것이다 이번 장에서 살펴볼 회귀모형은 다음의 단순회귀모형이다. \\[\\begin{equation} Y_{i} = \\beta_{0} + \\beta_{1}X_{i} + \\varepsilon_{i}, ~~i = 1, \\ldots, n \\tag{3.1} \\end{equation}\\] 2장에서 회귀계수를 최소제곱추정량으로 추정하기 위해서 필요한 가정은 다음과 같다. \\[\\begin{equation} \\varepsilon_{1}, \\ldots, \\varepsilon_{n} \\text{은 서로 독립이고}~E(\\varepsilon_{i})=0,~Var(\\varepsilon_{i})=\\sigma^{2} \\end{equation}\\] 회귀모형의 추론을 위해서는 위 가정에 정규분포 가정이 추가된 다음의 가정이 필요하게 된다. \\[\\begin{equation} \\varepsilon_{1}, \\ldots, \\varepsilon_{n} \\stackrel{iid}{\\sim} N(0,\\sigma^{2}) \\tag{3.2} \\end{equation}\\] 3.1 회귀계수 \\(\\beta_{1}\\)에 대한 추론 식 (3.1)에서 회귀계수 \\(\\beta_{1}\\)은 회귀직선의 기울기를 나타내는 모수로서, 설명변수 \\(X\\)를 한 단위 증가시켰을 때 반응변수 \\(Y\\)의 평균 변화량을 나타낸다. 회귀계수 \\(\\beta_{1}\\)의 점추정량은 2장에서 살펴본 최소제곱추정량으로 구할 수 있었는데, 이번 절에서는 \\(\\beta_{1}\\)의 신뢰구간 추정과 가설검정에 대해 살펴보고자 한다. 식 (3.1)으로 설정된 회귀모형이 주어진 자료를 적절하게 설명하고 있는지 여부는 점추정 결과만으로는 알 수 없다. 추정 결과의 정확성 또는 적절성 등에 대한 접근은 관련된 회귀계수의 신뢰구간 추정을 통해 확인할 수 있다. 또한 주어진 자료를 근거로 가설 \\(H_{0}:\\beta_{1}=0\\) 에 대한 검정이 필요한데, 만일 가설을 기각할 수 없다면, 반응변수 \\(Y\\)와 설명변수 \\(X\\)의 관계가 식 (3.1)에서 설정한 선형관계로는 설명하기 어렵다는 것을 의미하기 때문이다. 이러한 추론을 실시하기 위해서는 회귀계수 \\(\\beta_{1}\\)의 점추정량인 \\(\\hat{\\beta}_{1}\\)의 표본분포를 반드시 알고 있어야 한다. 3.1.1 \\(\\hat{\\beta}_{1}\\)의 표본분포 식 (3.1)의 회귀모형에 식 (3.2)에 주어진 오차항의 가정 사항을 적용시키면 설명변수 \\(X_{i}\\)가 주어졌을 때 반응변수 \\(Y_{i}\\)에 대한 분포는 다음과 같이 주어진다. \\[\\begin{equation} Y_{i} \\stackrel{iid}{\\sim} N(\\beta_{0}+\\beta_{1}X_{i}, \\sigma^{2}),~~i=1, \\ldots, n \\end{equation}\\] 2장에서 유도한 회귀계수 \\(\\beta_{1}\\)의 최소제곱추정량인 \\(\\hat{\\beta}_{1}\\)은 식 (2.7)에서 다음과 같이 반응변수 \\(Y_{i}\\)의 선형결합으로 표현됨을 보였다. \\[\\begin{equation} \\hat{\\beta}_{1} = \\sum_{i=1}^{n} c_{i}Y_{i},~~c_{i}= \\frac{X_{i}-\\overline{X}}{\\sum_{i=1}^{n}(X_{i}-\\overline{X})^{2}} \\end{equation}\\] 즉, \\(\\hat{\\beta}_{1}\\)은 정규분포를 하는 확률변수인 \\(Y_{i}\\)의 선형결합으로 표현되기 때문에 \\(\\hat{\\beta}_{1}\\)의 분포도 정규분포를 따르게 되는 것이다. 또한 식 (2.11)와 식 (2.13)에서 유도된 \\(\\hat{\\beta}_{1}\\)의 평균과 분산을 적용시키면 \\(\\hat{\\beta}_{1}\\)의 표본분포는 다음과 같이 주어진다. \\[\\begin{equation} \\hat{\\beta}_{1} \\sim N \\left( \\beta_{1}, \\frac{\\sigma^{2}}{\\sum_{i=1}^{n}(X_{i}-\\overline{X})^{2}} \\right) \\tag{3.3} \\end{equation}\\] 3.1.2 \\(\\beta_{1}\\)의 신뢰구간 모수 \\(\\beta_{1}\\)에 대한 신뢰구간은 하나의 숫자보다는 모수를 포함할 구간을 제시하는 것이며, 구간의 폭은 추정량의 표준오차에 비례하여 결정된다. 따라서 주어진 자료가 설정된 회귀모형에 의하여 잘 설명된다면 신뢰구간의 폭은 상대적으로 작은 값을 갖게 된다. 모수 \\(\\beta_{1}\\)의 신뢰구간은 모수의 불편추정량인 \\(\\hat{\\beta}_{1}\\)의 표본분포를 활용해서 유도되는데, 우선 식 (3.3)에서 다음의 결과를 얻을 수 있다. \\[\\begin{equation} Z = \\frac{\\hat{\\beta}_{1}-\\beta_{1}}{\\sqrt{\\sigma^{2}/\\sum_{i=1}^{n}(X_{i}-\\overline{X})^{2}}} \\sim N(0,1) \\end{equation}\\] 식 (2.17)에서 \\(\\sigma^{2}\\)의 불편추정량은 \\(MSE\\)임이 확인되었고, 이제 \\(\\sigma^{2}\\)를 \\(MSE\\)로 대체하면 다음의 결과를 얻게 된다. \\[\\begin{equation} t = \\frac{\\hat{\\beta}_{1}-\\beta_{1}}{\\sqrt{MSE/\\sum_{i=1}^{n}(X_{i}-\\overline{X})^{2}}} \\sim t(n-2) \\tag{3.4} \\end{equation}\\] 단, \\(t(n-2)\\)는 자유도가 \\(n-2\\)인 \\(t\\) 분포를 의미하는 것인데, 통계량 \\(t\\)의 자유도는 분모에 사용된 \\(MSE\\)의 자유도가 그대로 적용된다. 모수 \\(\\beta_{1}\\)의 \\(100 \\times (1-\\alpha)\\)% 신뢰구간은 식 (3.4)을 이용해서 다음과 같이 유도된다. \\[\\begin{align} 1-\\alpha &amp; = P \\left( -t_{\\alpha, n-2} &lt; \\frac{\\hat{\\beta}_{1}-\\beta_{1}}{SE(\\hat{\\beta}_{1})} &lt; t_{\\alpha, n-2} \\right) \\\\ &amp; = P \\left( \\hat{\\beta}_{1} - t_{\\alpha, n-2} \\cdot SE(\\hat{\\beta}_{1}) &lt; \\beta_{1} &lt; \\hat{\\beta}_{1} + t_{\\alpha, n-2} \\cdot SE(\\hat{\\beta}_{1}) \\right) \\tag{3.5} \\end{align}\\] 단, \\(SE(\\hat{\\beta}_{1})=\\sqrt{MSE/\\sum(X_{i}-\\overline{X})^{2}}\\) 를 나타내고, \\(t_{\\alpha, n-2}\\) 는 자유도가 \\(n-2\\)인 \\(t\\) 분포에서 상위 \\(100 \\times \\alpha\\) 백분위수를 나타낸다. 모수의 신뢰구간은 점추정량의 표본분포를 근거로 유도된 것이기 때문에, 식 (3.5)의 신뢰구간도 표본분포의 개념을 이용해서 해석해야 한다. 즉, 자료에 주어진 동일한 \\(X\\) 값에 대해서 표본을 반복해서 추출하고, 추출된 각 표본마다 식 (3.5)에 의해 95% 신뢰구간을 계산한다면, 계산된 전체 신뢰구간 중 대략 95%의 신뢰구간에는 미지의 모수인 \\(\\beta_{1}\\)이 포함되지만 나머지 5%의 신뢰구간에는 \\(\\beta_{1}\\)이 포함되지 않을 수 있다는 것이다. 따라서 실제 상황에서 우리가 얻게 되는 하나의 표본을 대상으로 계산된 신뢰구간에는 \\(\\beta_{1}\\)이 포힘되어 있는지 여부를 알 수 없는 것이다. 3.1.3 \\(\\beta_{1}\\)에 대한 가설검정 기울기에 대한 가설검정은 \\(\\beta_{1}\\) 이 특정한 상수인 \\(\\beta_{1o}\\) 와 같은 값을 갖는지 여부에 대한 것이다. \\[\\begin{equation} H_{0}:\\beta_{1} = \\beta_{1o}, ~~~H_{1}:\\beta_{1} \\ne \\beta_{1o} \\tag{3.6} \\end{equation}\\] 만일 \\(\\sigma^{2}\\) 가 알려져 있다면, 검정통계량은 다음과 같이 주어지며, \\[\\begin{equation} Z= \\frac{\\hat{\\beta}_{1}-\\beta_{1o}}{\\sqrt{\\sigma^{2}/\\sum_{i=1}^{n}(X_{i}-\\overline{X})^{2}}} \\tag{3.7} \\end{equation}\\] \\(H_{0}\\)이 사실인 경우, 분포는 \\(N(0,1)\\) 이 된다. 그러나 대부분의 상황에서는 \\(\\sigma^{2}\\) 의 값을 알기 어렵고, 따라서 \\(MSE\\) 로 추정한 결과를 대신 사용하게 된다. 이 경우에 검정통계량은 다음과 같이 주어지며, \\[\\begin{equation} t = \\frac{\\hat{\\beta}_{1}-\\beta_{1o}}{SE(\\hat{\\beta}_{1})} \\tag{3.8} \\end{equation}\\] 단, \\(SE(\\hat{\\beta}_{1}) = \\sqrt{MSE/\\sum_{i=1}^{n}(X_{i}-\\overline{X})^{2}}\\). \\(H_{0}\\)이 사실인 경우, 검정통계량의 분포는 \\(t(n-2)\\) 가 된다. 식 (3.6)의 가설 중 가장 중요한 경우는 \\(\\beta_{1o}=0\\) 이 되며, 이것을 회귀계수 \\(\\beta_{1}\\)의 유의성 검정이라고 한다. \\[\\begin{equation} H_{0}:\\beta_{1}=0,~~~H_{1}:\\beta_{1} \\ne 0 \\tag{3.9} \\end{equation}\\] \\(\\beta_{1}\\)의 유의성 검정에서 사용되는 검정통계량은 식 (3.8)에서 \\(\\beta_{1o}\\) 를 0으로 두는 형태가 된다. \\[\\begin{equation} t = \\frac{\\hat{\\beta}_{1}}{SE(\\hat{\\beta}_{1})} \\tag{3.10} \\end{equation}\\] 주어진 자료를 근거로 만일 \\(H_{0}\\) 을 기각할 수 없다면, 식 (3.1)에서 설정된 모형이 \\(Y_{i}=\\beta_{0}+\\varepsilon_{i}\\) 로 변경되는 것이며, 따라서 설명변수 \\(X\\)가 반응변수 \\(Y\\)의 변동 설명하는데 아무런 기여를 할 수 없다는 것을 의미하게 된다. 하지만 이것은 두 변수의 실제 관계가 선형이 아닌 경우에는 틀린 결론이 될 수 있다. 예시 자료를 활용해서 자세히 살펴보자. 그림 3.1은 두 변수 사이에 관계가 없는 경우에 대한 예시로서, 설명변수가 반응변수의 변동을 설명하는데 어떤 역할도 할 수 없는 상황으로 보인다. 파란 직선은 추정된 회귀직선을 나타내고 있는데, \\(H_{0}:\\beta_{1}=0\\) 을 기각하기 어려운 상황으로 보인다. 실제 예시 자료를 근거로 가설 \\(H_{0}:\\beta_{1}=0, ~~H_{1}:\\beta_{1} \\ne 0\\) 에 대한 검정을 실시한 결과 p-값은 0.859으로 계산되어 \\(H_{0}\\)은 기각할 수 없게 된다. 그림 3.1: \\(H_{0}:\\beta_{1}=0\\)을 기각할 수 없는 상황: 두 변수 사이에 관계가 없는 경우 그림 3.2는 두 변수의 관계가 선형이 아닌 2차 함수의 관계에 있는 경우에 대한 예시 자료이다. 추정된 기울기는 0에 가까운 값을 갖고 있고, 가설 \\(H_{0}:\\beta_{1}=0, ~~H_{1}:\\beta_{1} \\ne 0\\) 에 대한 검정 결과 p-값은 0.839으로 계산되어 \\(H_{0}\\) 을 기각하기 어려운 상황으로 보이지만, 두 변수 사이에는 명확한 관계가 있는 것을 알 수 있다. 그림 3.2: \\(H_{0}:\\beta_{1}=0\\)을 기각할 수 없는 상황: 두 변수 사이에 2차 함수 관계가 있는 경우 그림 3.3도 두 변수의 관계가 선형이 아닌 2차 함수의 관계에 있는 경우에 대한 예시 자료이다. 이 경우에는 기울기의 추정 결과가 0.376으로 나오며, 검정 결과에서도 p-값이 0.0112로 계산되어서 유의수준 \\(\\alpha = 0.05\\) 에서 \\(H_{0}\\)을 기각할 수 있는 자료이다. 하지만 \\(X^{2}\\)을 포함시킨 회구모형 \\(Y=\\beta_{0}+\\beta_{1}X+\\beta_{2}X^{2}+\\varepsilon\\) 이 더 적절한 모형으로 보인다. 그림 3.3: \\(H_{0}:\\beta_{1}=0\\)을 기각할 수 있지만, \\(X^{2}\\)을 포함한 2차 회귀모형이 더 좋은 결과를 보이는 경우 3.2 회귀계수 \\(\\beta_{0}\\)에 대한 추론 회귀계수 \\(\\beta_{0}\\) 는 회귀직선의 Y축 절편을 나타내는 모수로서, 설명변수 \\(X\\) 의 값이 0일 때 반응변수 \\(Y\\)의 평균값을 나타낸다. 따라서 설명변수가 갖는 자료의 범위에 0이 포함되지 않는 경우에는 추론의 필요성이 크지 않은 모수가 된다. 또한 가설 \\(H_{0}:\\beta_{0}=0\\) 을 기각할 수 없는 경우에도 일반적으로는 모형에서 \\(\\beta_{0}\\) 를 제외시키지 않는다. 3.2.1 \\(\\hat{\\beta}_{0}\\) 의 표본분포 2장에서 살펴본 \\(\\beta_{0}\\)의 최소제곱추정량은 식 (2.6)에서 다음과 같이 유도되었다. \\[\\begin{equation} \\hat{\\beta}_{0} = \\overline{Y} - \\hat{\\beta}_{1} \\overline{X} \\end{equation}\\] \\(\\hat{\\beta}_{1}\\) 이 식 (2.7)에서 \\(Y_{i}\\) 의 선형결합으로 표현됨을 알 수 있기 때문에 \\(\\hat{\\beta}_{0}\\) 도 자연스럽게 \\(Y_{i}\\) 의 선형결합으로 표현됨을 알 수 있다. 따라서 \\(\\hat{\\beta}_{0}\\) 도 \\(Y_{i}\\) 와 같은 분포인 정규분포를 따르게 된다. \\(\\hat{\\beta}_{0}\\) 의 평균과 분산은 식 (2.12)과 식 (2.14)에서 다음과 같이 유도되었다. \\[\\begin{align*} E\\left(\\hat{\\beta}_{0}\\right) &amp;= \\beta_{0} \\\\ Var\\left(\\hat{\\beta}_{0}\\right) &amp;= \\sigma^{2}\\left(\\frac{1}{n}+\\frac{\\overline{X}^{2}}{\\sum_{i=1}^{n}(X_{i}-\\overline{X})^{2}}\\right) \\end{align*}\\] 따라서 \\(\\hat{\\beta}_{0}\\) 의 표본분포는 다음과 같이 나타낼 수 있다. \\[\\begin{equation} \\hat{\\beta}_{0} ~ N\\left(\\beta_{0},~ \\sigma^{2}\\left(\\frac{1}{n}+\\frac{\\overline{X}^{2}}{\\sum_{i=1}^{n}(X_{i}-\\overline{X})^{2}}\\right) \\right) \\end{equation}\\] 3.2.2 \\(\\beta_{0}\\)의 신뢰구간 모수 \\(\\beta_{0}\\) 의 신뢰구간은 3.1.2절에서 \\(\\beta_{1}\\)의 신뢰구간을 유도할 때 사용했던 것과 동일한 방식으로 유도할 수 있다. 우선 \\(\\beta_{0}\\) 의 불편추정량인 \\(\\hat{\\beta}_{0}\\) 을 표준화시킨 통계량 \\(t\\) 는 다음과 같이 표현되며, 분포는 \\(\\hat{\\beta}_{1}\\) 의 경우와 동일하게 \\(t(n-2)\\)가 된다. \\[\\begin{equation} t = \\frac{\\hat{\\beta}_{0}-\\beta_{0}}{\\sqrt{MSE\\left(\\frac{1}{n}+\\frac{\\overline{X}^{2}}{\\sum_{i=1}^{n}(X_{i}-\\overline{X})^{2}}\\right)}} \\sim t(n-2) \\tag{3.11} \\end{equation}\\] 모수 \\(\\beta_{0}\\) 의 \\(100 \\times (1-\\alpha)\\)% 신뢰구간은 식 (3.11)을 이용하면 다음과 같이 유도된다. \\[\\begin{align} 1-\\alpha &amp; = P \\left( -t_{\\alpha, n-2} &lt; \\frac{\\hat{\\beta}_{0}-\\beta_{0}}{SE(\\hat{\\beta}_{0})} &lt; t_{\\alpha, n-2} \\right) \\\\ &amp; = P \\left( \\hat{\\beta}_{0} - t_{\\alpha, n-2} \\cdot SE(\\hat{\\beta}_{0}) &lt; \\beta_{0} &lt; \\hat{\\beta}_{0} + t_{\\alpha, n-2} \\cdot SE(\\hat{\\beta}_{0}) \\right) \\tag{3.12} \\end{align}\\] 단, \\(SE(\\hat{\\beta}_{0})=\\sqrt{MSE\\left(\\frac{1}{n}+\\frac{\\overline{X}^{2}}{\\sum(X_{i}-\\overline{X})^{2}}\\right)}\\) 을 나타내며, \\(t_{\\alpha, n-2}\\) 는 자유도가 \\(n-2\\)인 \\(t\\) 분포에서 상위 \\(100 \\times \\alpha\\) 백분위수를 나타낸다. 3.2.3 \\(\\beta_{0}\\)에 대한 가설검정 모수 \\(\\beta_{0}\\) 에 대한 가설검정도 3.1.3절에서 살펴본 \\(\\beta_{1}\\) 의 가설검정의 경우와 동일한 방식으로 진행할 수 있다. 다음의 가설에 대하여 \\[\\begin{equation} H_{0}: \\beta_{0} = 0, ~~H_{1}: \\beta_{0} \\ne 0 \\end{equation}\\] 검정정통계량은 식 (3.11)을 근거로 다음과 같이 주어진다. \\[\\begin{equation} t = \\frac{\\hat{\\beta}_{0}}{SE(\\hat{\\beta}_{0})} \\tag{3.13} \\end{equation}\\] 단, \\(SE(\\hat{\\beta}_{0})=\\sqrt{MSE\\left(\\frac{1}{n}+\\frac{\\overline{X}^{2}}{\\sum(X_{i}-\\overline{X})^{2}}\\right)}\\). \\(H_{0}\\) 이 사실일 때 검정통계량은 분포는 \\(t(n-2)\\)가 된다. 절차는 \\(\\beta_{1}\\) 의 경우와 동일하지만, 검정 결과의 적용 방식에는 큰 차이가 있다. \\(\\beta_{0}\\) 는 설명변수 \\(X\\) 의 값이 0일 때 반응변수 \\(Y\\)의 평균값을 나타내기 때문에, 설명변수가 갖는 자료의 범위에 0이 포함되지 않는 경우에는 추론의 필요성이 크지 않은 모수가 된다. 또한 가설 \\(H_{0}:\\beta_{0}=0\\) 을 기각할 수 없는 경우에도 모형에서 \\(\\beta_{0}\\) 를 제외시키지 않기 때문에, \\(\\beta_{0}\\) 에 대한 가설검정은 일반적으로 무시된다고 할 수 있다. 만일 가설 \\(H_{0}:\\beta_{0}=0\\) 의 검정 결과에 따라 모형에서 \\(\\beta_{0}\\) 를 제외시키게 되면, 회귀직선은 반드시 원점을 지나가야 하는데, 이것은 지나치게 강력한 제한사항이라고 할 수 있다. 예시 자료를 이용해서 이 문제를 살펴보자. 주어진 자료에 대해 식 (3.1)에 설정된 절편이 포함된 일반적인 단순회귀모형으로 추정된 회귀직선과 원점을 제거한 회귀모형인 \\(Y=\\beta_{1}X+\\varepsilon\\) 으로 추정된 회귀직선이 그림 3.4에 표시되어 있다. 주어진 자료에서 가설 \\(H_{0}:\\beta_{0}=0, ~~H_{1}:\\beta_{0} \\ne 0\\) 에 대한 p-값은 0.248으로 계산되어 \\(H_{0}\\) 을 기각할 수 없는 상황이다. 두 회귀직선 사이에는 무시할 수 없는 차이가 있는 것으로 보이는데, 절편이 포함된 회귀직선의 경우에는 잔차제곱합이 \\(RSS=\\) 118.98인 반면에, 절편이 제거되어 원점을 지나는 회귀직선의 경우에는 잔차제곱합이 \\(RSS=\\) 124.89로 계산된다. 따라서 가설검정의 결과에 따라 절편을 제거한 회귀모형의 적합도가 더 떨어지는 것을 볼 수 있다. 그림 3.4: 절편을 제거한 회귀모형의 한계 \\(\\bullet\\) 예제 3.1: 매출액에 대한 광고효과 회귀모형의 회귀계수에 대한 추론 예제 2.2의 자료 ex2-2.csv에 대하여 다음의 분석을 실시해 보자. 광고비 지출이 매출액 증가에 양의 효과가 있는지 검정하라. 기울기 모수인 \\(\\beta_{1}\\)에 대한 95% 신뢰구간을 추정하라. 회귀모형의 적합은 함수 lm()으로 이루어진다. 적합된 회귀모형에 대한 추론을 위해서는 lm()으로 생성된 객체에 다른 함수를 적용시켜 생성된 객체를 대상으로 이루어진다. 추론을 위해 사용되는 가장 대표적인 함수는 summary()이다. 자료 ex2-2.csv를 대상으로 회귀모형을 적합시켜보자. df2.2 &lt;- readr::read_csv(&quot;Data/ex2-2.csv&quot;) fit2.2 &lt;- lm(sales ~ advertisement, data = df2.2) 함수 lm()으로 생성된 객체 fit2.2에 회귀모형의 추론 단계에서 가장 빈번하게 사용되는 함수 summary()를 적용시킨 결과를 확인해 보자. summary(fit2.2) ## ## Call: ## lm(formula = sales ~ advertisement, data = df2.2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -158.433 -15.093 0.557 21.674 151.973 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -6.944 52.004 -0.134 0.895 ## advertisement 17.713 1.685 10.511 4.13e-09 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 60.41 on 18 degrees of freedom ## Multiple R-squared: 0.8599, Adjusted R-squared: 0.8521 ## F-statistic: 110.5 on 1 and 18 DF, p-value: 4.126e-09 함수 summary()의 결과물은 SAS나 SPSS에서 볼 수 있는 결과물과는 형식에서 차이가 있으나, 많은 정보를 매우 효율적으로 보여주는 방식이라고 하겠다. 결과물을 하나씩 살펴보자. 먼저 Residuals:에는 잔차의 분포 형태를 엿볼 수 있는 요약통계가 계산되어 있다. 가정이 만족된다면 평균이 0인 정규분포를 보이게 되는데, 잔차의 요약통계 결과로 대략적인 판단을 할 수 있다. 잔차에 대한 분석은 5장에서 살펴볼 것이다. Coefficients:에는 회귀계수의 추정값이 Estimate에, 표준오차가 Std. Error에 각각 계산되어 있다. 또한 개별 회귀계수의 유의성 검정인 \\(H_{0}:\\beta_{j} = 0, ~~H_{1}: \\beta_{j} \\ne 0\\) 에 대한 검정통계량의 값이 t value에, p-값이 Pr(&gt;|t|)이 각각 계산되어 있다. Residual standard error:는 식 (2.17)에서 정의된 \\(MSE\\) 에 제곱근을 취한 값으로 \\(\\sigma\\) 에 대한 추정 결과이며, 회귀모형의 평가 측도로 사용된다. Multiple R-squared:와 Adjusted R-squared:, 그리고 F-statistic:의 내용은 추후에 살펴보겠다. 이제 예제 문제를 해결해 보자. 광고비 지출이 매출액 증가에 양의 효과가 있는지 여부를 확인하는 것은 식 (3.9)와는 다르게 다음과 같은 단측검정이 된다. \\[\\begin{equation} H_{0}:\\beta_{1}=0, ~~H_{1}:\\beta_{1}&gt;0 \\tag{3.14} \\end{equation}\\] 광고비 지출이 매출액 증가에는 음의 효과가 있을 수 없다는 확신이 있는 경우에만 적용할 수 있는 가설이며, 가설은 반드시 자료를 조사하기 전에 설정되어야 한다. 함수 summary()에서 계산한 p-값은 식 (3.9)의 양측검정에 대한 것으로서, \\(P(t &gt; |t_{0}|)\\) 을 계산한 것이다. 여기에서 \\(t\\) 는 자유도가 \\((n-2)\\) 인 \\(t\\) 분포이고 \\(|t_{0}|\\) 는 자료에서 계산된 검정통계량 값을 나타낸다. 식 (3.14)의 단측검정에 대한 p-값은 \\(P(t&gt;t_{0})\\)가 되는데, 예제 자료에서는 \\(t_{0}=\\) 17.713으로 양수이므로 함수 summary()에서 계산한 p-값을 2로 나누면 된다. 따라서 양의 효과가 있는지 여부를 확인하는 가설의 p-값은 2.063186e-09 이 되어서, \\(H_{0}\\) 을 기각하는데 문제가 없어 보인다. 즉, 광고비 지출이 매출액 증가에 양의 효과가 있는 것으로 볼 수 있다. 회귀계수에 대한 신뢰구간은 함수 lm()으로 생성된 객체를 함수 confint()에 적용시키면 얻을 수 있다. 함수 confint()의 기본적인 사용법은 confint(object, level = 0.95)인데, object는 함수 lm()으로 생성된 객체이고, level은 신뢰수준을 지정하는 것으로서 95%가 디폴트 값이다. 이제 광고비 자료에 대한 회귀모형 객체인 fit2.2를 함수 confint()에 적용시킨 결과를 살펴보자. confint(fit2.2) ## 2.5 % 97.5 % ## (Intercept) -116.20070 102.31274 ## advertisement 14.17241 21.25336 만일 90% 신뢰구간을 계산하고자 한다면, level = 0.9를 추가하면 된다. confint(fit2.2, level = 0.9) ## 5 % 95 % ## (Intercept) -97.12253 83.23457 ## advertisement 14.79064 20.63513 3.3 반응변수의 평균, \\(E(Y|X_{o})\\)에 대한 신뢰구간 추정 새롭게 관측되는 설명변수 자료에 대한 가장 정확한 반응변수의 예측값을 생성하는 것이 회귀분석의 목적이 되는 경우가 많이 있다. 반응변수의 예측값은 대부분의 경우 반응변수의 평균을 의미하는데, 경우에 따라서는 반응변수의 개별 관측값을 예측하고자 하는 경우도 있을 수 있다. 반응변수의 평균 예측에 대한 문제는 이번 절에서 살펴볼 것이고, 반응변수의 개별 관측값 예측에 대한 문제는 다음 절에서 살펴볼 것이다. 식 (3.1)의 회귀모형에 의하면, 반응변수 \\(Y\\) 의 평균값은 설명변수의 값에 따라 다른 값을 갖게 된다. 따라서 반응변수의 평균을 예측하고자 하는 설명변수의 수준을 먼저 지정해야 하는데, 이 값을 \\(X_{o}\\) 라고 하자. 그러면 지정된 설명변수 수준에 대한 반응변수의 평균값은 \\(E(Y|X_{o})\\) 가 되는데, 이 때 설명변수의 수준 \\(X_{o}\\) 는 현재 분석에 사용된 자료의 범위 내에서 지정하는 것이 안전하다. 그 이유는 그림 1.4에서 살펴본 회귀모형의 유의성 문제로 인하여, 현재 수집된 자료 범위를 벗어난 영역에 대해서는 가급적 예측을 실시하지 않는 것이 안전하기 때문이다. \\(E(Y|X_{o})=\\beta_{0}+\\beta_{1}X_{o}\\) 에 대한 불편추정량은 \\(\\beta_{0}\\) 와 \\(\\beta_{1}\\) 에 대한 불편추정량을 각각 적용시켜서 다음과 같이 주어진다. \\[\\begin{equation} \\widehat{E(Y|X_{o})} \\equiv \\widehat{Y}_{o} = \\hat{\\beta}_{0} + \\hat{\\beta}_{1}X_{o} \\tag{3.15} \\end{equation}\\] \\(E(Y|X_{o})\\) 에 대한 신뢰구간을 추정하기 위해서는 \\(E(Y|X_{o})\\) 의 불편추정량인 \\(\\widehat{Y}_{o}\\) 의 표본분포를 유도해야 한다. \\(\\widehat{Y}_{o}\\) 은 \\(\\hat{\\beta}_{0}\\) 와 \\(\\hat{\\beta}_{1}\\) 의 선형결합으로 이루어져 있는데, \\(\\hat{\\beta}_{0}\\) 와 \\(\\hat{\\beta}_{1}\\) 은 2.2.2절에서 살펴보았지만 모두 \\(Y_{i}\\) 의 선형결합으로 표현된다. 따라서 \\(\\widehat{Y}_{o}\\) 은 \\(Y_{i}\\) 와 동일하게 정규분포를 따르게 된다. 또한 \\(\\widehat{Y}_{o}\\) 의 분산은 다음과 같이 유도할 수 있다. \\[\\begin{align} Var(\\widehat{Y}_{o}) &amp;= Var(\\hat{\\beta}_{0}+\\hat{\\beta}_{1}X_{o}) \\\\ &amp;= Var(\\overline{Y}-\\hat{\\beta}_{1}\\overline{X}+\\hat{\\beta}_{1}X_{O}) \\\\ &amp;= Var(\\overline{Y}+\\hat{\\beta}_{1}(X_{o}-\\overline{X})) \\\\ &amp;= \\frac{\\sigma^{2}}{n}+\\frac{(X_{o}-\\overline{X})^{2}\\cdot \\sigma^{2}}{\\sum_{i=1}^{n}(X_{i}-\\overline{X})^{2}} \\\\ &amp;= \\sigma^{2}\\left(\\frac{1}{n}+\\frac{(X_{o}-\\overline{X})^{2}}{\\sum_{i=1}^{n}(X_{i}-\\overline{X})^{2}}\\right) \\tag{3.16} \\end{align}\\] 식 (3.16)의 세 번째에서 네 번째 단계로 넘어오는 과정에는 \\(Cov(\\overline{Y}, \\hat{\\beta}_{1})=0\\) 이 필요한데, 이것의 증명은 2장 연습문제로 주어졌다. 따라서 \\(\\widehat{Y}_{o}\\) 의 표본분포는 다음과 같다. \\[\\begin{equation} \\widehat{Y}_{o} \\sim N\\left(\\beta_{0}+\\beta_{1}X_{o},~\\sigma^{2}\\left(\\frac{1}{n}+\\frac{(X_{o}-\\overline{X})^{2}}{\\sum_{i=1}^{n}(X_{i}-\\overline{X})^{2}}\\right) \\right) \\end{equation}\\] \\(E(Y|X_{o})\\) 의 불편추정량인 \\(\\widehat{Y}_{o}\\) 을 표준화시킨 통계량 \\(t\\) 는 다음과 같이 표현되며, 분포는 \\(\\hat{\\beta}_{1}\\)의 경우와 동일하게 \\(t(n-2)\\) 가 된다. \\[\\begin{equation} t = \\frac{\\widehat{Y}_{o}-E(Y|X_{o})}{\\sqrt{MSE\\left(\\frac{1}{n}+\\frac{(X_{o}-\\overline{X})^{2}}{\\sum_{i=1}^{n}(X_{i}-\\overline{X})^{2}}\\right)}} \\tag{3.17} \\end{equation}\\] 모수 \\(E(Y|X_{o})\\) 의 \\(100 \\times (1-\\alpha)\\)% 신뢰구간은 식 (3.17)을 이용하면 다음과 같이 유도된다. \\[\\begin{align} 1-\\alpha &amp;= P\\left(-t_{\\alpha, n-2}&lt;\\frac{\\widehat{Y}_{o}-E(Y|X_{o})}{SE(\\widehat{Y}_{o})}&lt;t_{\\alpha, n-2} \\right) \\\\ &amp;= P\\left(\\widehat{Y}_{o}-t_{\\alpha, n-2}\\cdot SE(\\widehat{Y}_{o}) &lt; E(Y|X_{o}) &lt; \\widehat{Y}_{o}+t_{\\alpha, n-2}\\cdot SE(\\widehat{Y}_{o})\\right) \\tag{3.18} \\end{align}\\] 단, \\(SE(\\widehat{Y}_{o})) = \\sqrt{MSE\\left(\\frac{1}{n}+\\frac{(X_{o}-\\overline{X})^{2}}{\\sum_{i=1}^{n}(X_{i}-\\overline{X})^{2}}\\right)}\\) 을 나타내며, \\(t_{\\alpha, n-2}\\) 는 자유도가 \\((n-2)\\) 인 \\(t\\) 분포의 상위 \\(100 \\times \\alpha\\) 백분위수를 나타낸다. 식 (3.18)의 신뢰구간에서 확인할 수 있는 것은 신뢰구간의 폭이 \\(X_{o} = \\overline{X}\\) 일 때 최소가 되며, \\(|X_{o}-\\overline{X}|\\) 의 값이 증가함에 따라 점점 넓어진다는 점이다. 즉, \\(E(Y|X_{o})\\) 에 대한 추정은 \\(X_{o}\\) 의 값이 자료의 평균에 가까우면 좋은 결과를 기대할 수 있지만, 그렇지 않은 경우에는 신뢰도가 많이 떨어질 수 있다는 것을 의미한다. 3.4 반응변수의 개별 관측값 예측 이번 절에서는 주어진 설명변수의 수준에 대한 반응변수의 개별 관측값 예측에 대한 문제를 살펴보겠다. 이번 절에서도 미리 지정되는 설명변수의 수준을 \\(X_{o}\\) 라고 하고, \\(X_{o}\\) 에 해당하는 새로운 관측값을 \\(Y_{o}\\) 라고 하자. 새로운 관측값 \\(Y_{o}\\) 는 식 (3.1)의 회귀모형에 의해서 다음과 같이 주어진다. \\[\\begin{equation} Y_{o} = \\beta_{0} + \\beta_{1}X_{o} + \\varepsilon_{o} \\end{equation}\\] \\(Y_{o}\\) 의 점추정량 \\(\\widehat{Y}_{o}\\) 을 구하기 위해서는 \\(\\beta_{0}\\) 와 \\(\\beta_{1}\\) 을 각각의 불편추정량으로 대체하고, 확률변수인 \\(\\varepsilon_{o}\\) 은 \\(N(0,\\sigma^{2})\\) 에 따른 임의의 값을 갖게 되기 때문에 정확한 값을 예측할 수 없는 대상이어서 평균값 0으로 적용시켜서 다음과 같이 구할 수 있다. \\[\\begin{equation} \\widehat{Y}_{o} = \\hat{\\beta}_{0} + \\hat{\\beta}_{1}X_{o} \\tag{3.19} \\end{equation}\\] 따라서 개별 관측값 \\(Y_{o}\\) 와 평균 관측값 \\(E(Y|X_{o})\\) 는 식 (3.15)와 (3.19)에 주어진 동일한 점추정량 \\(\\widehat{Y}_{o}\\) 을 갖게 된다. \\(Y_{o}\\) 에 대한 예측구간을 추정하기 위해 다음의 확률변수를 고려해 보자. \\[\\begin{equation} \\psi = \\widehat{Y}_{o}-Y_{o} \\end{equation}\\] 확률변수 \\(\\psi\\) 는 \\(Y_{i}\\) 와 동일한 분포를 하기 때문에 정규분포를 따르고 있으며, 평균은 다음과 같고, \\[\\begin{align*} E(\\psi) &amp;= E(\\widehat{Y}_{o}-Y_{o}) \\\\ &amp;= E(\\hat{\\beta}_{o}+\\hat{\\beta}_{1}X_{o}) - E(\\beta_{0} + \\beta_{1}X_{o} + \\varepsilon_{o}) \\\\ &amp;= 0 \\end{align*}\\] 분산은 다음과 같이 유도된다. \\[\\begin{align*} Var(\\psi) &amp;= Var(\\widehat{Y}_{o}-Y_{o}) \\\\ &amp;= Var(\\widehat{Y}_{o}) + Var(Y_{o}) \\\\ &amp;= \\sigma^{2}\\left(\\frac{1}{n}+\\frac{(X_{o}-\\overline{X})^{2}}{\\sum_{i=1}^{n}(X_{i}-\\overline{X})^{2}}\\right) + \\sigma^{2} \\\\ &amp; = \\sigma^{2}\\left(1+\\frac{1}{n}+\\frac{(X_{o}-\\overline{X})^{2}}{\\sum_{i=1}^{n}(X_{i}-\\overline{X})^{2}}\\right) \\end{align*}\\] 확률변수 \\(\\psi\\) 를 표준화시킨 통계량 \\(t\\) 는 다음과 같이 표현되며, 분포는 \\(t(n-2)\\) 가 된다. \\[\\begin{equation} t = \\frac{\\widehat{Y}_{o}-Y_{o}}{SE(\\psi)} \\end{equation}\\] 단, \\(SE(\\psi) = \\sqrt{MSE\\left(1+\\frac{1}{n}+\\frac{(X_{o}-\\overline{X})^{2}}{\\sum_{i=1}^{n}(X_{i}-\\overline{X})^{2}}\\right)}\\). 따라서 미리 지정되는 설명변수의 수준 \\(X_{o}\\) 에 대해 새롭게 관측될 개별 반응변수 값 \\(Y_{o}\\) 의 \\(100 \\times (1-\\alpha)\\)% 예측구간은 다음과 같이 주어진다. \\[\\begin{align*} 1-\\alpha &amp;= P\\left(-t_{\\alpha, n-2}&lt;\\frac{\\widehat{Y}_{o}-Y_{o}}{SE(\\psi)}&lt;t_{\\alpha, n-2} \\right) \\\\ &amp;= P\\left(\\widehat{Y}_{o}-t_{\\alpha, n-2}\\cdot SE(\\psi) &lt; Y_{o} &lt; \\widehat{Y}_{o}+t_{\\alpha, n-2}\\cdot SE(\\psi)\\right) \\tag{3.20} \\end{align*}\\] 지정된 설명변수 수준 \\(X_{o}\\) 에 대한 반응변수의 평균에 대한 신뢰구간과 반응변수의 개별 관측값에 대한 예측구간의 폭을 비교해 보면, 식 (3.20)의 예측구간이 식 (3.18)의 신뢰구간보다 항상 더 넓다는 것을 알 수 있다. 이것은 예측구간이 \\(E(Y|X_{o})\\) 을 \\(\\widehat{Y}_{o}\\) 으로 추정하는 과정에서 발생하는 오차와 새로운 관측값 \\(Y_{o}\\) 에 의해 발생하는 오차를 모두 포함하기 때문이다. \\(\\bullet\\) 예제 3.2: 매출액에 대한 광고효과 회귀모형에서 매출액의 신뢰구간과 예측구간 추정 예제 2.2 자료 ex2-2.csv에 대하여 다음의 분석을 실시해 보자. 모형 적합에 사용된 광고비 자료에 대한 평균 매출액의 95% 신뢰구간과 매출액의 개별 관측값에 대한 95% 예측구간을 구하라. 피자 체인점들이 광고비를 25, 30, 35, 40을 각각 지출하면 얻게 될 것으로 예상되는 매출액의 평균은 어떻게 되는가? 평균 매출액에 대한 95% 신뢰구간을 구하라. 수원에 있는 어느 특정 피자 체인점이 광고비를 25, 30, 35, 40을 각각 지출하면 얻게 될 것으로 예측되는 매출액의 95% 예측구간을 구하라. 적합된 회귀모형의 예측에 사용되는 함수는 predict()이다. 함수 lm()으로 생성된 회귀모형 객체에 대한 predict()의 기본적인 사용법은 다음과 같다. predict(object, newdata, interval = c(&quot;none&quot;, &quot;confidence&quot;, &quot;prediction&quot;)) object는 함수 lm()으로 생성된 객체이고, newdata는 새롭게 주어지는 설명변수의 값으로 반드시 데이터 프레임으로 입력되어야 하며, 생략이 되면 모형적합에 사용된 자료에 대한 예측이 이루어진다. interval은 구간의 종류를 선택하는 것으로서, 평균 반응변수에 대한 신뢰구간은 \"confidence\", 반응변수의 개별 관측값에 대한 예측구간은 \"prediction\"을 선택하면 되고, 신뢰구간을 원하지 않는 경우에는 \"none\"을 선택하면 된다. 디폴트는 \"none\"이다. 자료 ex2-2.csv에 대하여 회귀모형 객체 fit2.2를 생성하자. df2.2 &lt;- read_csv(&quot;Data/ex2-2.csv&quot;) fit2.2 &lt;- lm(sales ~ advertisement, data = df2.2) 예제의 첫 번째 문제는 모형적합에 사용된 광고비 자료에 대한 예측이다. 따라서 함수 predict()에 newdata를 지정하지 않고 interval을 \"confidence\"와 \"prediction\"을 각각 지정해서 평균 반응변수에 대한 신뢰구간과 개별 관측값에 대한 예측구간을 구하면 된다. pred_1 &lt;- predict(fit2.2, interval = &quot;confidence&quot;) pred_2 &lt;- predict(fit2.2, interval = &quot;prediction&quot;) 두 구간의 폭은 그래프로 비교해 보자. library(patchwork) p1 &lt;- cbind(df2.2, pred_1) |&gt; ggplot(aes(x = advertisement, y = sales)) + geom_point() + geom_ribbon(aes(ymin = lwr, ymax = upr), alpha = 0.1, fill = &quot;pink&quot;, color = &quot;red&quot;, linewidth = 1) + ggtitle(&quot;반응변수 평균에 대한 신뢰구간&quot;) p2 &lt;- cbind(df2.2, pred_2) |&gt; ggplot(aes(x = advertisement, y = sales)) + geom_point() + geom_ribbon(aes(ymin = lwr, ymax = upr), alpha = 0.1, fill = &quot;skyblue&quot;, color = &quot;blue&quot;, linewidth = 1) + ggtitle(&quot;반응변수 개별 관측값에 대한 예측구간&quot;) p1 + p2 그림 3.5: 매출액 자료에 대한 신뢰구간과 예측구간 비교 예제의 두 번째와 세 번째 문제는 새롭게 주어진 설명변수 값에 대하여 평균 매출액에 대한 신뢰구간과 개별 관측값에 대한 예측구간을 추정하는 문제이다. 새롭게 주어진 설명변수 값을 데이터 프레임으로 지정하고, 예측을 실시해 보자. new_data &lt;- data.frame(advertisement = c(25, 30, 35, 40)) pred_3 &lt;- predict(fit2.2, newdata = new_data, interval = &quot;confidence&quot;) pred_4 &lt;- predict(fit2.2, newdata = new_data, interval = &quot;prediction&quot;) 신뢰구간의 폭은 새롭게 주어지는 설명변수의 값이 자료의 평균인 29.8에 가까울수록 작아진다. new_data |&gt; cbind(pred_3) |&gt; mutate(width = upr - lwr) ## advertisement fit lwr upr width ## 1 25 435.8782 402.7979 468.9584 66.16044 ## 2 30 524.4426 496.0525 552.8327 56.78018 ## 3 35 613.0070 579.1774 646.8366 67.65917 ## 4 40 701.5714 655.6407 747.5022 91.86146 예측구간은 폭도 신뢰구간의 경우와 동일하게 자료의 평균에 가까울수록 작아지지만, 이 예제의 경우에는 상대적으로 큰 차이가 없는 것을 알 수 있다. new_data |&gt; cbind(pred_4) |&gt; mutate(width = upr - lwr) ## advertisement fit lwr upr width ## 1 25 435.8782 304.7133 567.0430 262.3297 ## 2 30 524.4426 394.3814 654.5038 260.1224 ## 3 35 613.0070 481.6512 744.3628 262.7117 ## 4 40 701.5714 566.5916 836.5512 269.9596 3.5 단순회귀모형에서 두 변수 사이의 연관성 측정: 상관계수 두 변수 사이의 선형 관련성을 측정하는 통계량으로 식 (2.2)에 정의된 공분산이 있다. 공분산의 값이 크면 두 변수 사이에 강한 양의 관계 또는 음의 관계가 있다고 할 수 있지만, 값이 작으면 선형 관계가 명확하지 않다고 할 수 있다. 그러나 공분산은 변수가 취하는 값 자체의 절대적 크기에도 영향을 받는 통계량이기 때문에, ‘값이 크다’ 또는 ’값이 작다’에 대한 절대적 기준을 제시할 수 없는데, 이 문제는 두 변수의 표준편차를 나누어 값을 상대화시킴으로서 해결할 수 있다. 이것이 두 변수의 상관계수 \\(\\rho\\) 가 된다. \\[\\begin{equation} \\rho = \\frac{Cov(Y,X)}{\\sqrt{Var(Y)}\\sqrt{Var(X)}} \\tag{3.21} \\end{equation}\\] 상관계수는 \\(-1 \\leq \\rho \\leq 1\\) 의 범위를 취하고 있는데, \\(1\\)과 \\(-1\\)이 되면 두 변수가 완벽한 선형관계를 갖게 되고, \\(0\\)에 가까울수록 명확한 선형관계가 없는 경우가 된다. 그림 3.6은 상관관계의 값에 따라 두 변수의 산점도에 어떤 변화가 생길 수 있는지를 보여주는 모의자료에 대한 산점도이다. 그림 3.6: 상관계수와 두 변수 산점도 형태 공분산이나 상관계수는 두 변수가 모두 확률변수인 경우에 적용되는 개념이다. 그러나 식 (2.1)에서 설정한 회귀모형에서 설명변수 \\(X\\) 는 분석자가 통제할 수 있는 변량이고, 반응변수만 확률변수라고 가정하였다. 하지만 설명변수 \\(X\\) 의 수준을 분석자가 임의로 조절하는 것이 불가능한 경우가 많이 있으며, 이런 상황에서는 변수 \\(Y\\) 와 \\(X\\) 가 모두 확률변수가 된다. 예를 들어 그림 1.5에서 다루고 있는 일일 최고 기온과 전기 사용량의 관계에서 설명변수인 일일 최고 기온의 수준은 분석자가 임의로 선택할 수 없는 변량이 된다. 또한 예제 2.2에서 다루고 있는 매출액에 대한 광고비 효과 자료에서도 실제로 우리는 피자 체인점을 임의로 선택해서 지출된 광고비와 매출액을 관측하는 것이기 때문에 광고비 수준을 분석자가 미리 설정하는 것은 어려운 상황이라고 할 수 있다. 이와 같이 설명변수도 확률변수인 경우에는 관측된 설명변수의 수준을 조건부로 하여 회귀모형에 대한 추론을 실시하게 된다. 식 (3.21)에 주어진 모수 \\(\\rho\\) 는 다음의 표본 상관계수로 추정할 수 있다. \\[\\begin{equation} r = \\frac{\\sum_{i=1}^{n} (X_{i}-\\overline{X})(Y_{i}-\\overline{Y})}{\\sqrt{\\sum_{i=1}^{n} (X_{i}-\\overline{X})^{2}}\\sqrt{\\sum_{i=1}^{n}(Y_{i}-\\overline{Y})^{2}}} \\tag{3.22} \\end{equation}\\] 상관계수의 유의성 검정은 다음의 가설에 대한 검정이다. \\[\\begin{equation} H_{0}: \\rho = 0,~~H_{1}:\\rho \\ne 0 \\end{equation}\\] 검정통계량 \\(t\\) 는 다음과 같이 주어지며, \\(H_{0}\\) 이 사실인 경우의 분포는 \\(t(n-2)\\) 가 된다. \\[\\begin{equation} t = \\frac{r \\sqrt{n-2}}{\\sqrt{1-r^{2}}} \\end{equation}\\] 상관계수의 유의성 검정으로 \\(H_{0}\\) 이 기각되면, 두 변수 사이에 유의한 선형관계가 있다는 것을 의미한다. 하지만 그렇다고 해서 두 변수 사이에 강한 선형관계가 있다는 것을 의미하는 것은 아니다. 그림 3.6에서 상관계수 값이 -0.29인 자료의 산점도를 보면 두 변수 사이에는 마치 선형관계가 없는 것으로 보인다. 하지만 상관계수의 유의성 검정을 실시하면 조금 다른 결과를 얻게 되는데, 상관계수의 유의성 검정은 함수 cor.test()로 할 수 있다. cor.test(x,y) ## ## Pearson&#39;s product-moment correlation ## ## data: x and y ## t = -2.0846, df = 48, p-value = 0.04245 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## -0.52441468 -0.01062909 ## sample estimates: ## cor ## -0.2881244 검정 결과는 두 변수 사이에 유의한 선형관계가 존재하는 것으로 나왔다. "],["multiple-reg.html", "4 장 다중회귀모형 4.1 다중회귀모형의 설정 4.2 다중회귀모형의 추론 4.3 변수선택", " 4 장 다중회귀모형 반응변수의 변동을 하나의 설명변수만으로 충분하게 설명하는 것은 대부분의 경우 불가능할 것이다. 따라서 반응변수와 관련이 있을 것으로 보이는 여러 개의 설명변수를 모형에 포함시키는 다중회귀모형이 실제 상황에서 많이 사용되는 모형이 된다. 기본 가정 및 추론 방법에서는 단순회귀모형과 큰 차이가 있는 것은 아니지만, 모형에 여러 개의 설명변수가 포함되기 때문에 단순회귀모형에서는 없었던 문제들이 발생할 수 있다. 4.1 다중회귀모형의 설정 다중선형회귀모형에서는 반응변수 \\(Y\\) 와 설명변수 \\(X_{1}, \\ldots, X_{k}\\) 사이에 다음의 관계가 존재한다고 가정한다. \\[\\begin{equation} Y_{i} = \\beta_{0} + \\beta_{1}X_{1i} + \\cdots + \\beta_{k}X_{ki} + \\varepsilon_{i},~~i=1,\\ldots,n \\tag{4.1} \\end{equation}\\] \\(Y_{i}\\) 는 반응변수의 \\(i\\) 번째 값, \\(X_{ji}\\) 는 설명변수 \\(X_{j}\\) 의 \\(i\\) 번째 값을 나타내며, 모수 \\(\\beta_{0}, \\beta_{1}, \\ldots, \\beta_{k}\\) 는 \\((k+1)\\) 차원의 공간에서 정의되는 회귀평면을 구성하고 있다. 오차항 \\(\\varepsilon_{i}\\) 은 단순회귀모형에서와 동일한 의미를 갖고 있는 확률변수로서, \\(\\varepsilon_{i} \\stackrel{iid}{\\sim} N(0,\\sigma^{2}),~i=1,\\ldots,n\\) 의 가정을 하고 있다. 식 (4.1)의 관계식은 다음과 같이 풀어서 표현할 수 있으며, \\[\\begin{align*} Y_{1} &amp;= \\beta_{0} + \\beta_{1}X_{11} + \\cdots + \\beta_{k}X_{k1} + \\varepsilon_{1} \\\\ Y_{2} &amp;= \\beta_{0} + \\beta_{1}X_{12} + \\cdots + \\beta_{k}X_{k2} + \\varepsilon_{2} \\\\ \\vdots \\\\ Y_{n} &amp;= \\beta_{0} + \\beta_{1}X_{1n} + \\cdots + \\beta_{k}X_{kn} + \\varepsilon_{n} \\end{align*}\\] 이것은 다시 다음과 같이 행렬의 형태로 정리할 수 있다. \\[ \\begin{pmatrix} Y_{1} \\\\ Y_{2} \\\\ \\vdots \\\\ Y_{n} \\end{pmatrix} = \\begin{pmatrix} 1 &amp; X_{11} &amp; \\cdots &amp; X_{k1} \\\\ 1 &amp; X_{12} &amp; \\cdots &amp; X_{k2} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 1 &amp; X_{1n} &amp; \\cdots &amp; X_{kn} \\end{pmatrix} \\begin{pmatrix} \\beta_{0} \\\\ \\beta_{1} \\\\ \\vdots \\\\ \\beta_{k} \\end{pmatrix} + \\begin{pmatrix} \\varepsilon_{1} \\\\ \\varepsilon_{2} \\\\ \\vdots \\\\ \\varepsilon_{n} \\end{pmatrix} \\tag{4.2} \\] 또는 다음의 행렬로 표현할 수 있다. \\[\\begin{equation} \\mathbf{Y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon} \\tag{4.3} \\end{equation}\\] \\(\\mathbf{Y}\\) 는 반응변수의 관찰값 벡터이고, \\(\\mathbf{X}\\) 는 설명변수의 관찰값 행렬로써 design matrix라고 하며, \\(\\boldsymbol{\\beta}\\) 는 모수 벡터, \\(\\boldsymbol{\\varepsilon}\\) 은 오차항 벡터이다. 4.1.1 회귀계수의 추정 회귀계수 \\(\\beta_{0}, \\beta_{1}, \\ldots, \\beta_{k}\\) 의 추정은 단순회귀모형의 경우와 동일한 방식으로 이루어진다. 반응변수 \\(Y\\) 와 설명변수 \\(X_{1}, \\ldots, X_{k}\\) 에 대해 관측된 \\(n\\) 개의 자료를 \\((y_{i}, x_{1i}, \\ldots, x_{ki}), ~i=1,\\ldots,n\\) 이라고 하면, 다음의 \\(RSS\\) 를 최소화하는 \\(\\hat{\\boldsymbol{\\beta}} = (\\hat{\\beta}_{0}, \\hat{\\beta}_{1}, \\ldots, \\hat{\\beta}_{k})\\) 를 선택한다. \\[\\begin{equation} RSS = \\sum_{i=1}^{n} \\left(y_{i} - \\hat{\\beta}_{0} - \\hat{\\beta}_{1}x_{1i} - \\ldots - \\hat{\\beta}_{k}x_{ki} \\right)^{2} \\tag{4.4} \\end{equation}\\] 식 (4.4)의 \\(RSS\\) 를 최소화시키는 추정값 \\(\\hat{\\beta}_{0}, \\ldots, \\hat{\\beta}_{k}\\) 를 구하기 위해서 \\(RSS\\) 를 \\(\\hat{\\beta}_{j}, ~j = 0, \\ldots, k\\) 에 대하여 각각 편미분을 실시해서 다음의 \\((k+1)\\) 개의 방정식을 얻는다. \\[\\begin{align} \\frac{\\partial RSS}{\\partial \\hat{\\beta}_{0}} &amp; = -2 \\sum_{i=1}^{n}(y_{i}-\\hat{\\beta}_{0}-\\hat{\\beta}_{1}x_{1i}-\\cdots-\\hat{\\beta}_{k}x_{ki}) = 0\\\\ \\frac{\\partial RSS}{\\partial \\hat{\\beta}_{1}} &amp; = -2 \\sum_{i=1}^{n}x_{1i}(y_{i}-\\hat{\\beta}_{0}-\\hat{\\beta}_{1}x_{1i}-\\cdots-\\hat{\\beta}_{k}x_{ki}) = 0 \\\\ &amp;\\vdots \\\\ \\frac{\\partial RSS}{\\partial \\hat{\\beta}_{k}} &amp; = -2 \\sum_{i=1}^{n}x_{ki}(y_{i}-\\hat{\\beta}_{0}-\\hat{\\beta}_{1}x_{1i}-\\cdots-\\hat{\\beta}_{k}x_{ki}) = 0 \\tag{4.5} \\end{align}\\] 식 (4.5)을 정리하면 다음과 같이 표현이 되며, \\[\\begin{align} n\\hat{\\beta}_{0}+\\hat{\\beta}_{1}\\sum_{i=1}^{n} x_{1i} + \\cdots + \\hat{\\beta}_{k}\\sum_{i=1}^{n} x_{ki} &amp;= \\sum_{i=1}^{n} y_{i} \\\\ \\hat{\\beta}_{0}\\sum_{i=1}^{n} x_{1i} + \\hat{\\beta}_{1}\\sum_{i=1}^{n} x_{1i}^{2} + \\cdots + \\hat{\\beta}_{k} \\sum_{i=1}^{n} x_{1i}x_{ki} &amp;= \\sum_{i=1}^{n} x_{1i}y_{i} \\\\ &amp; \\vdots \\\\ \\hat{\\beta}_{0}\\sum_{i=1}^{n} x_{ki} + \\hat{\\beta}_{1}\\sum_{i=1}^{n} x_{ki}x_{1i} + \\cdots + \\hat{\\beta}_{k}\\sum_{i=1}^{n} x_{ki}^{2} &amp;= \\sum_{i=1}^{n} x_{ki}y_{i} \\tag{4.6} \\end{align}\\] 행렬의 형태로 표현하면 다음과 같이 된다. \\[ \\begin{pmatrix} n &amp; \\sum x_{1i} &amp; \\cdots &amp; \\sum x_{ki} \\\\ \\sum x_{1i} &amp; \\sum x_{1i}^{2} &amp; \\cdots &amp; \\sum x_{1i}x_{ki} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\sum x_{ki} &amp; \\sum x_{ki}x_{1i} &amp; \\cdots &amp; \\sum x_{ki}^{2} \\end{pmatrix} \\begin{pmatrix} \\hat{\\beta}_{0} \\\\ \\hat{\\beta}_{1} \\\\ \\vdots \\\\ \\hat{\\beta}_{k} \\end{pmatrix}= \\begin{pmatrix} 1 &amp; 1 &amp; \\cdots &amp; 1 \\\\ x_{11} &amp; x_{12} &amp; \\cdots &amp; x_{1n} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ x_{k1} &amp; x_{k2} &amp; \\cdots &amp; x_{kn} \\end{pmatrix} \\begin{pmatrix} y_{1} \\\\ y_{2} \\\\ \\vdots \\\\ y_{n} \\end{pmatrix} \\tag{4.7} \\] 식 (4.7)의 좌변 첫 번째 행렬은 식 (4.3)에서 정의된 행렬 \\(\\mathbf{X}\\) 로 다음과 같이 표현된다. \\[ \\begin{pmatrix} n &amp; \\sum x_{1i} &amp; \\cdots &amp; \\sum x_{ki} \\\\ \\sum x_{1i} &amp; \\sum x_{1i}^{2} &amp; \\cdots &amp; \\sum x_{1i}x_{ki} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\sum x_{ki} &amp; \\sum x_{ki}x_{1i} &amp; \\cdots &amp; \\sum x_{ki}^{2} \\end{pmatrix}= \\mathbf{X}^{T}\\mathbf{X} \\tag{4.8} \\] 단, \\(\\mathbf{X}^{T}\\) 는 행렬 \\(\\mathbf{X}\\) 의 전치행렬이다. 따라서 다중회귀모형의 회귀계수에 대한 최소제곱추정량을 구하기 위한 방정식은 다음과 같이 주어진다. \\[\\begin{equation} \\mathbf{X}^{T}\\mathbf{X}\\hat{\\boldsymbol{\\beta}} = \\mathbf{X}^{T}\\mathbf{Y} \\tag{4.9} \\end{equation}\\] 만일 \\(\\mathbf{X}^{T}\\mathbf{X}\\) 의 역행렬이 존재한다면, 최소제곱추정량은 다음과 같이 표현된다. \\[\\begin{equation} \\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^{T}\\mathbf{X})^{-1}\\mathbf{X}^{T}\\mathbf{Y} \\tag{4.10} \\end{equation}\\] \\(\\bullet\\) 예제 4.1 : 다중회귀모형의 회귀계수 추정 데이터 프레임 mtcars는 1974년 \\(\\textit{Motor Trend US}\\) 에 실린 32 종류 자동차 모델의 연비와 관련된 자료가 입력되어 있다. str(mtcars) ## &#39;data.frame&#39;: 32 obs. of 11 variables: ## $ mpg : num 21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ... ## $ cyl : num 6 6 4 6 8 6 8 4 4 6 ... ## $ disp: num 160 160 108 258 360 ... ## $ hp : num 110 110 93 110 175 105 245 62 95 123 ... ## $ drat: num 3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ... ## $ wt : num 2.62 2.88 2.32 3.21 3.44 ... ## $ qsec: num 16.5 17 18.6 19.4 17 ... ## $ vs : num 0 0 1 1 0 1 0 1 1 1 ... ## $ am : num 1 1 1 0 0 0 0 0 0 0 ... ## $ gear: num 4 4 4 3 3 3 3 4 4 4 ... ## $ carb: num 4 4 1 1 2 1 4 2 2 4 ... 연비를 나타내는 mpg를 반응변수로 하고, 설명변수에는 차량의 무게를 나타내는 wt와 0.25 마일까지 도달하는 데 걸리는 시간을 나타내는 qsec을 선택해서 다중회귀모형을 설정하고 회귀계수를 추정해 보자. 단순회귀모형의 경우와 동일하게 다중회귀모형에서도 함수 lm()을 사용해서 모형적합을 실시할 수 있다. 하지만 단순회귀모형의 경우와 다르게 설명변수의 개수가 2개 이상이 되며, 복잡한 형태의 모형이 설정되는 경우도 많이 있기 때문에 다중회귀모형의 경우에는 함수 lm()에 지정되는 R 모형공식에 반응변수와 설명변수를 구분하는 ~ 기호 외에도 많은 기호가 사용된다. R 모형공식에서 사용되는 기호 기호 사용법 물결표 (~) 반응변수와 설명변수의 구분. 물결표의 왼쪽에는 반응변수, 오른쪽에는 설명변수를 둔다. 플러스 (+) 모형에 포함된 설명변수의 구분. 반응변수 y와 설명변수 x1, x2, x3의 회귀모형은 y ~ x1 + x2 + x3로 표현된다. 콜론 (:) 설명변수 사이의 상호작용 표현. 반응변수 y와 설명변수 x1, x2 그리고 x1과 x2의 상호작용이 포함된 모형은 y ~ x1 + x2 + x1:x2로 표현된다. 별표 (*) 주효과와 상호작용 효과를 포함한 모든 효과 표현. y ~ x1 * x2 * x3는 y ~ x1 + x2 + x3 + x1:x2 + x1:x3 + x2:x3 + x1:x2:x3를 의미한다. 윗꺽쇠 (^) 지정된 차수까지의 상호작용 표현. y ~ (x1 + x2 + x3)^2는 y ~ x1 + x2 + x3 + x1:x2 + x1:x3 + x2:x3을 의미한다. 점 (.) 반응변수를 제외한 데이터 프레임에 있는 모든 변수. 만일 데이터 프레임에 y, x1, x2, x3가 있다면 y ~ . 은 y ~ x1 + x2 + x3을 의미한다. 마이너스(-) 회귀모형에서 제외되는 변수. y ~ (x1 + x2 + x3)^2 – x2:x3는 y ~ x1 + x2 + x3 + x1:x2 + x1:x3을 의미한다. - 1, + 0 절편 제거. y ~ x – 1 혹은 y ~ x + 0은 원점을 지나는 회귀모형을 의미한다. I() 괄호 안의 연산자를 수학 연산자로 인식. y ~ x1 + I(x2+x3)는 \\(y=\\beta_{0}+\\beta_{1}x_{1}+\\beta_{2}(x_{2}+x_{3})+\\varepsilon\\) 모형을 의미한다. 이제 mpg를 반응변수로, wt와 qsec을 설명변수로 하는 다중회귀모형을 적합해 보자. fit4.1 &lt;- lm(mpg ~ wt + qsec, data = mtcars) fit4.1 ## ## Call: ## lm(formula = mpg ~ wt + qsec, data = mtcars) ## ## Coefficients: ## (Intercept) wt qsec ## 19.7462 -5.0480 0.9292 적합된 모형식은 \\(\\widehat{\\mbox{mpg}} = 19.74 - 5.047\\mbox{ wt} + 0.929\\mbox{ qsec}\\) 임을 알 수 있다. 추정된 회귀계수에 대한 해석은 단순회귀모형의 경우와 비슷하지만 제한 사항이 추가된다. 단순회귀모형에서는 하나의 설명변수만 있기 때문에 추정된 모형은 직선으로 표현되고, 따라서 해당 설명변수가 한 단위 증가했을 때 반응변수의 평균 변화량으로 회귀계수를 해석할 수 있었다. 하지만 다중회귀모형에서는 추정된 회귀모형이 직선이 아닌 2차원 이상에서 정의되는 평면이 되기 때문에 조금 더 복잡한 상황이 되는데, 그것은 어느 한 설명변수의 효과를 측정하기 위해서는 회귀평면을 구성하고 있는 다른 설명변수의 값이 고정되어야 하기 때문이다. 그림 4.1에서는 mpg를 반응변수로, wt와 qsec을 설명변수로 하는 다중회귀모형으로 적합된 회귀평면이 작성되어 있다. 변수 wt의 추정된 회귀계수 \\(-5.047\\) 은 qsec을 일정한 수준으로 고정한 상태에서 wt가 한 단위 증가했을 때 mpg의 평균 변화량을 나타내는 것인데, 그림에서 회귀평면이 wt 축의 양의 방향으로 급격하게 기우는 모습을 볼 수 있다. 또한 변수 qsec에 대한 추정된 회귀계수 \\(0.929\\) 은 wt를 일정한 수준으로 고정한 상태에서 qsec이 한 단위 증가했을 때 mpg의 평균 변화량을 나타내는 것이며, 그림에서 회귀평면이 qsec의 양의 방향으로 완만하게 증가하는 모습을 볼 수 있다. 그림 4.1: 설명변수가 2개인 다중회귀모형에서 추정된 회귀평면 \\(\\bullet\\) 예제 4.2: 행렬 state.x77 행렬 state.x77은 미국 50개 주와 관련된 8개 변수로 구성되었다. 변수 Life Exp와 HS Grad는 이름 중간에 빈칸이 있으며, 각 주의 이름이 행렬의 row name으로 입력되어 있음을 알 수 있다. state.x77[1:5,] ## Population Income Illiteracy Life Exp Murder HS Grad Frost Area ## Alabama 3615 3624 2.1 69.05 15.1 41.3 20 50708 ## Alaska 365 6315 1.5 69.31 11.3 66.7 152 566432 ## Arizona 2212 4530 1.8 70.55 7.8 58.1 15 113417 ## Arkansas 2110 3378 1.9 70.66 10.1 39.9 65 51945 ## California 21198 5114 1.1 71.71 10.3 62.6 20 156361 변수 Murder를 반응변수로, 나머지 7개 변수를 설명변수로 하는 다중회귀모형을 설정해 보자. 회귀분석을 원활하게 수행하기 위해서는 자료가 행렬이 아닌 데이터 프레임의 형태로 입력되어 있어야 한다. 행렬 state.x77을 데이터 프레임으로 변환하면서, 빈칸이 있는 변수 이름을 수정하고 반응변수를 마지막 변수로 이동시키자. states &lt;- as_tibble(state.x77) |&gt; rename(Life_Exp = `Life Exp`, HS_Grad = `HS Grad`) |&gt; relocate(Murder, .after = last_col()) |&gt; print(n = 3) ## # A tibble: 50 × 8 ## Population Income Illiteracy Life_Exp HS_Grad Frost Area Murder ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 3615 3624 2.1 69.0 41.3 20 50708 15.1 ## 2 365 6315 1.5 69.3 66.7 152 566432 11.3 ## 3 2212 4530 1.8 70.6 58.1 15 113417 7.8 ## # ℹ 47 more rows 행렬을 tibble로 전환시켰기 때문에 각 주의 이름이 입력된 row name이 삭제되었는데, 만일 row name를 그대로 유지하고자 한다면 함수 as_tibble() 대신 as.data.frame()을 사용하면 된다. 반응변수의 위치를 마지막으로 이동시킨 이유는 산점도 행렬을 작성하고 결과를 해석할 때 더 편리하기 때문이다. 다중회귀모형에 의한 분석을 진행하기 전에 반드시 거쳐야 할 단계가 있는데, 그것은 모형에 포함될 변수들의 관계를 탐색하는 것이다. 변수들 사이의 관계 탐색에 많이 사용되는 방법은 상관계수와 산점도행렬이다. 산점도행렬과 같은 그래프에 의한 탐색은 필수적이라 할 수 있으며, 연속형 변수의 경우에는 두 변수끼리 짝을 지어 상관계수를 살펴보는 것도 필요하다. 상관계수는 변수들 사이의 선형관계 정도를 확인할 때 사용할 수 있는데, 함수 cor()로 계산할 수 있다. 사용법은 cor(x, y = NULL, use = \"everything\", method = c(\"pearson\", \"kendall\", \"spearman\"))이다. x와 y 모두 벡터, 행렬 혹은 데이터 프레임이 가능한데, x만 주어지면 x에 포함된 모든 변수들 사이의 상관계수를 계산하게 되고, y도 주어지면 x에 속한 변수와 y에 속한 변수들을 하나씩 짝을 지어 상관계수를 계산하게 된다. use는 결측값의 처리방식에 대한 것으로 선택할 수 있는 것은 디폴트인 \"everything\"과 \"all.obs\", \"complete.obs\", \"pairwise.complete.obs\"이 있으며, 해당 문자의 약칭으로도 사용이 가능하다. 결측값이 존재하면 use = \"everything\"인 경우에는 NA가 계산결과로 출력되고, use = \"all\"인 경우에는 오류가 발생한다. 또한 use = \"complete\"의 경우에는 NA가 있는 행은 모두 제거된 상태에서 상관계수가 계산되고, use = \"pairwise\"의 경우에는 상관계수가 계산되는 변수들만을 대상으로 NA가 있는 행을 제거하고 상관계수를 계산한다. method는 계산하는 상관계수의 종류를 선택한다. 디폴트인 \"pearson\"은 Pearson의 상관계수를 지정하는 것으로 두 변수 사이의 선형관계 정도를 표현하는 가장 일반적으로 많이 사용되는 상관계수를 계산한다. 두 번째 방법인 \"kendall\"은 Kendall의 순위상관계수 혹은 Kendall의 \\(\\tau\\) 를 지정하는 것으로서 concordant pair와 discordant pair를 이용하여 정의되는 비모수 상관계수를 계산하며, 순서형 자료에 주로 적용되는 방법이다. 세 번째 방법인 \"spearman\"은 Spearman의 순위상관계수 혹은 Spearman의 \\(\\rho\\) 를 지정하는 것으로서 두 변수 사이의 관계가 단조증가 혹은 단조감소 함수로 얼마나 잘 설명될 수 있는지를 표현하는 비모수 상관계수를 계산한다. 정규성 가정이 어긋나는 경우에 사용할 수 있다. 데이터 프레임 states를 구성하고 있는 변수들의 상관계수를 구해보자. cor(states) ## Population Income Illiteracy Life_Exp HS_Grad ## Population 1.00000000 0.2082276 0.10762237 -0.06805195 -0.09848975 ## Income 0.20822756 1.0000000 -0.43707519 0.34025534 0.61993232 ## Illiteracy 0.10762237 -0.4370752 1.00000000 -0.58847793 -0.65718861 ## Life_Exp -0.06805195 0.3402553 -0.58847793 1.00000000 0.58221620 ## HS_Grad -0.09848975 0.6199323 -0.65718861 0.58221620 1.00000000 ## Frost -0.33215245 0.2262822 -0.67194697 0.26206801 0.36677970 ## Area 0.02254384 0.3633154 0.07726113 -0.10733194 0.33354187 ## Murder 0.34364275 -0.2300776 0.70297520 -0.78084575 -0.48797102 ## Frost Area Murder ## Population -0.3321525 0.02254384 0.3436428 ## Income 0.2262822 0.36331544 -0.2300776 ## Illiteracy -0.6719470 0.07726113 0.7029752 ## Life_Exp 0.2620680 -0.10733194 -0.7808458 ## HS_Grad 0.3667797 0.33354187 -0.4879710 ## Frost 1.0000000 0.05922910 -0.5388834 ## Area 0.0592291 1.00000000 0.2283902 ## Murder -0.5388834 0.22839021 1.0000000 함수 cor()에 데이터 프레임을 입력하면 모든 변수들 사이의 상관계수가 행렬 형태로 계산되어 출력된다. 상관계수행렬은 변수의 개수가 많아지면 변수 사이의 관계 파악이 어려워지는 문제가 있다. 이런 경우에는 그래프로 표현하는 것이 더 효과적인 방법이 될 것이다. 패키지 GGally의 함수 ggcorr()은 상관계수행렬을 그래프로 표현할 때 많이 사용되는 함수이다. 사용법은 ggcorr(data, method = c(\"pairwise\", \"pearson\"), label = FALSE, label_round = 1, ...)이다. method는 결측값 처리 방식과 계산되는 상관계수의 종류를 차례로 지정하는데, 디폴트는 \"pairwise\"와 \"pearson\"이다. label은 그래프에 상관계수를 표시할 것인지 여부를 결정하는 것이고, label_round는 표시되는 상관계수의 반올림 자릿수를 지정한다. 데이터 프레임 states를 구성하고 하는 변수들의 상관계수를 그래프로 나타내 보자. 숫자로만 구성되어 있는 상관계수행렬보다 훨씬 간편하게 변수 사이의 상관관계를 파악할 수 있다. library(GGally) ggcorr(states, label = TRUE, label_round = 2) 그림 4.2: 함수 ggcorr()에 의한 상관계수 그래프 반응변수를 마지막 변수로 이동시켰기 때문에 반응변수와 다른 설명변수 사이의 상관계수를 편하게 확인할 수 있다. 반응변수 Murder가 설명변수 Illiteracy와는 비교적 높은 양의 상관관계를, Life_Exp와는 비교적 높은 음의 상관관계를 보이고 있다. 상관계수는 두 변수 사이의 선형관계 정도만을 측정하는 측도이다. 변수 사이에 존재하는 ’있는 그대로’의 관계를 확인하는 가장 좋은 방법은 산점도행렬이다. 함수 GGally::ggpairs()로 작성해 보자. ggpairs(states, lower = list(continuous = &quot;smooth&quot;)) 그림 4.3: 함수 ggpairs()에 의한 산점도행렬 반응변수를 마지막 변수로 위치를 이동시켰기 때문에 산점도행렬의 마지막 행을 이루고 있는 모든 패널에서 Murder가 Y축 변수로 배치되고, 설명변수들이 각각 X축 변수로 배치되었다. 이제 states 자료에 대한 회귀모형을 함수 lm()으로 적합해 보자. fit4.2 &lt;- lm(Murder ~ ., data = states) fit4.2 ## ## Call: ## lm(formula = Murder ~ ., data = states) ## ## Coefficients: ## (Intercept) Population Income Illiteracy Life_Exp HS_Grad ## 1.222e+02 1.880e-04 -1.592e-04 1.373e+00 -1.655e+00 3.234e-02 ## Frost Area ## -1.288e-02 5.967e-06 함수 lm()으로 생성된 객체 fit4.2을 단순하게 출력시키면 추정된 회귀계수만 나타나지만, 사실 객체 fit4.2는 많은 양의 정보가 담겨 있는 리스트이며, 이것은 획득하기 위해서는 몇 가지 함수를 사용해야 한다. 함수 목록은 아래 표에 정리되어 있으며, 사용하는 방법은 앞으로 살펴보겠다. 함수 lm() 으로 생성된 객체에서 필요한 결과를 얻기 위해 유용하게 사용되는 함수 함수 산출 결과 anova() 추정된 회귀모형의 분산분석표 혹은 두 개 이상의 추정된 모형을 비교하기 위한 분산분석표 coefficients() 추정된 회귀계수. coef()도 가능. confint() 회귀계수의 신뢰구간. 95% 신뢰구간이 디폴트. deviance() 잔차제곱합(residual sum of squares; RSS), \\(\\sum (y_{i}-\\hat{y}_{i})^{2}\\) fitted() 반응변수의 적합값, \\(\\hat{y}_{i}\\) residuals() 회귀모형의 잔차, \\(e_{i}=y_{i}-\\hat{y}_{i}\\) . resid()도 가능. summary() 회귀모형의 다양한 적합 결과 4.1.2 다항회귀모형 식 (4.1)에 정의된 다중회귀모형에서는 반응변수와 설명변수 사이의 관계가 선형이라고 가정하고 있다. 하지만 두 변수의 관계가 그림 1.3와 같이 명확한 2차 함수 관계가 있을 경우에는 설명변수의 제곱항을 모형에 추가하는 다항회귀모형이 더 적절한 대안이 될 수 있다. 단순회귀모형에 대한 \\(p\\) 차 다항회귀모형은 다음과 같이 설정된다. \\[\\begin{equation} Y = \\beta_{0} + \\beta_{1}X + \\beta_{2}X^{2} + \\cdots + \\beta_{p}X^{p} + \\varepsilon \\tag{4.11} \\end{equation}\\] 차수 \\(p\\) 는 가능한 낮게 잡는 것이 좋은데, 그것은 너무 높은 차수의 항을 모형에 포함시키면 \\(\\left( \\mathbf{X}^{T} \\mathbf{X} \\right)^{-1}\\) 가 불안정해질 수 있고, 따라서 회귀계수 추정에 문제가 생길 수 있기 때문이다. 이 문제는 ’다중공선성’을 소개할 때 다시 살펴보겠다. 일단 차수가 선택되면, 선택된 차수 이하의 모든 차수는 반드시 모형에 포함되어야 한다. 예를 들어 \\(Y=\\beta_{0}+\\beta_{1}X+\\beta_{2}X^{2}+\\varepsilon\\) 모형에서 어떠한 이유에서 \\(X\\) 의 1차항을 제거한다면, 모형은 \\(Y=\\beta_{0}+\\beta_{2}X^{2}+\\varepsilon\\) 가 되는데, 이 모형은 Y축을 중심으로 좌우대칭을 이루어야 하는 지나치게 강한 가정을 갖게 된다. 또한 만일 변수 \\(X\\) 의 값을 \\(a\\) 만큼 평행 이동시켜야 한다면, \\(X\\) 가 \\(X+a\\) 로 변경되어 다음과 같이 모형에 다시 1차항이 나타나게 된다. \\[\\begin{align*} Y &amp;= \\beta_{0} + \\beta_{2}(X+a)^{2} + \\varepsilon \\\\ &amp;= \\beta_{0} + \\beta_{2}(X^{2} + 2aX + a^{2}) + \\varepsilon \\end{align*}\\] 설명변수가 2개인 다중회귀모형에서 2차 다항회귀모형은 다음과 같은 형태가 될 수 있다. \\[\\begin{equation} Y = \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + \\beta_{3}X_{1}^{2} + \\beta_{4}X_{2}^{2} + \\varepsilon \\tag{4.12} \\end{equation}\\] \\(\\bullet\\) 예제 4.3 : women 데이터 프레임 women에는 미국 30대 여성의 키(height)와 몸무게(weight)가 입력되어 있다. 두 변수 height와 weight의 회귀모형을 설정해 보자. 먼저 두 변수의 관계가 선형인지 여부를 그래프로 확인해 보자. ggplot(women, aes(x = height, y = weight)) + geom_point(size = 3) + geom_smooth(aes(color = &quot;loess&quot;), se = FALSE) + geom_smooth(aes(color = &quot;linear&quot;), method=&quot;lm&quot;, se = FALSE) + labs(color = &quot;&quot;) 그림 4.4: 데이터 프레임 women의 변수 height와 weight의 산점도와 선형회귀직선 및 국소회귀곡선 두 변수의 관계가 선형보다는 2차 곡선이 더 적합한 것으로 보인다. 다항회귀모형은 함수 poly()를 이용하거나 또는 함수 I()를 이용해서 적합할 수 있다. 함수 poly()는 함수 lm()과 함께 lm(y ~ poly(x, degree = 1, raw = FALSE), data)와 같이 사용할 수 있다. degree는 다항회귀모형의 차수를 지정하는 것으로 디폴트 값은 1차이고, raw는 직교다항회귀(orthogonal polynomial regression)의 사용 여부를 선택하는 것으로서 디폴트 값인 FALSE는 직교다항회귀에 의한 적합이 된다. 따라서 일반적인 다항회귀모형을 사용하고자 한다면 반드시 raw에 TRUE를 지정해야 한다. 차수가 높지 않은 일반적인 다항회귀모형을 적합하는 경우에는 함수 I()를 사용하는 것이 더 간편할 수 있다. 함수 lm() 안에서 lm(y ~ x + I(x^2), data)와 같이 입력하면 2차 다항회귀모형을 적합하게 된다. 반응변수 weight에 대한 설명변수 height의 2차 다항회귀모형을 적합해 보자. fit_w &lt;- lm(weight ~ height + I(height^2), women) fit_w ## ## Call: ## lm(formula = weight ~ height + I(height^2), data = women) ## ## Coefficients: ## (Intercept) height I(height^2) ## 261.87818 -7.34832 0.08306 적합된 회귀모형식은 \\(\\hat{y}_{i}=261.87 - 7.348x_{i} + 0.08x_{i}^{2}\\) 임을 알 수 있다. 4.1.3 가변수 회귀모형 선형회귀모형에서 반응변수는 유형이 반드시 연속형이어야 하며, 정규분포의 가정이 필요하다. 반면에 설명변수는 연속형 변수와 범주형 변수가 모두 가능한데, 연속형인 경우에는 정규분포의 가정은 필요 없으나 가능한 좌우대칭에 가까운 분포를 하는 것이 좋다. 범주형 변수 중 순서형 변수인 경우에는 연속형 변수처럼 변수의 값을 그대로 사용하는 것이 가능하지만, 명목형 변수의 경우에는 변수의 값을 그대로 사용하면 절대로 안 되고, 반드시 가변수(dummy variable)를 대신 사용해야 한다. 가변수를 설정하는 방식은 몇 가지가 있는데, 그 중 회귀계수 \\(\\beta_{0}\\) 를 유지하는 방식을 살펴보자. 이 경우, 가변수는 0 또는 1의 값을 갖게 되며, 범주의 개수보다 하나 작은 개수의 가변수를 사용하게 된다. 예를 들어, “Yes”, “No”와 같은 2개의 범주를 갖는 범주형 변수와 연속형 변수 \\(X\\) 를 설명변수로 하는 회귀모형은 다음과 같이 하나의 가변수를 갖게 된다. \\[\\begin{equation} Y = \\beta_{0} + \\beta_{1}X + \\beta_{2}D + \\varepsilon \\tag{4.13} \\end{equation}\\] 가변수 \\(D\\) 가 “Yes” 범주이면 1, “No” 범주이면 0을 값으로 갖는다면, 모집단 회귀직선은 다음과 같이 주어진다. \\[ E(Y) = \\begin{cases} \\beta_{0} + \\beta_{1}X &amp; \\quad \\text{if } D = 0 \\\\ \\beta_{0} + \\beta_{2} + \\beta_{1}X &amp; \\quad \\text{if } D = 1 \\end{cases} \\] \\(D=0\\) 이 되는 범주를 ’기준범주’라고 하는데, 절편 \\(\\beta_{0}\\) 가 기준범주의 효과를 나타내고 있고, 가변수의 회귀계수 \\(\\beta_{2}\\) 는 기준범주와 “Yes” 범주의 효과 차이를 나타내고 있다. 식 (4.13)의 회귀모형에서는 반응변수 \\(Y\\) 와 설병변수 \\(X\\) 가 “Yes”와 “No” 범주에서 동일한 관계를 갖고 있다고 가정하고 있는데, 만일 각 범주에서 두 변수의 관계가 다를 수 있다면 기울기도 다르게 설정할 필요가 있다. \\[\\begin{equation} Y = \\beta_{0} + \\beta_{1}X + \\beta_{2}D + \\beta_{3}DX + \\varepsilon \\tag{4.14} \\end{equation}\\] 범주형 변수가 3개의 범주를 갖는 경우에는 2개의 가변수가 필요하게 된다. 예를 들어 “high”, “medium”, “low”의 3가지 범주를 갖는 범주형 변수와 연속형 변수 \\(X\\) 를 설명변수로 하는 회귀모형은 다음과 같은 형태를 갖게 된다. 반응변수 \\(Y\\) 와 설병변수 \\(X\\) 가 세 범주에 동일한 관계를 갖고 있다고 가정하자. \\[\\begin{equation} Y = \\beta_{0} + \\beta_{1}X + \\beta_{2}D_{1} + \\beta_{3}D_{2} + \\varepsilon \\end{equation}\\] 단, \\(D_{1}\\) 은 범주가 “high”이면 1, 아니면 0이고, \\(D_{2}\\) 는 범주가 “medium”이면 1, 아니면 0이 되는 가변수이다. 이 경우, 기준범주는 “low”가 되며, \\(\\beta_{2}\\) 는 기준범주와 “high” 범주의 효과 차이를, \\(\\beta_{3}\\) 은 기준범주와 “medium” 범주의 효과 차이를 나타내고 있다. \\(\\bullet\\) 예제 4.4 : carData::Leinhardt carData::Leinhardt는 1970년대 105개 나라의 신생아 사망률, 소득, 지역 및 원유 수출 여부 자료가 입력되어 있다. 반응변수를 신생아 시망률(infant)로 하고, 나머지 변수인 소득(income), 원유 수출 여부(oil)과 지역(region)을 설명변수로 설정하자. 변수 oil은 'no'와 'yes'의 2개 범주를 갖고 있고, 변수 region은 'Africa', 'America', 'Asia', 'Europe'의 4개 범주를 갖고 있다. data(Leinhardt, package = &quot;carData&quot;) Leinhardt |&gt; head() ## income infant region oil ## Australia 3426 26.7 Asia no ## Austria 3350 23.7 Europe no ## Belgium 3346 17.0 Europe no ## Canada 4751 16.8 Americas no ## Denmark 5029 13.5 Europe no ## Finland 3312 10.1 Europe no 산점도행렬을 작성해 보자. 변수 income과 infant의 분포가 오른쪽 꼬리가 매우 긴 형태를 갖고 있으며, oil이 'yes'인 자료가 매우 드물다는 것을 알 수 있다. library(GGally) ggpairs(Leinhardt) 그림 4.5: Leinhardt 변수의 산점도 행렬 반응변수의 경우에 정규분포 가정이 있지만, 설명변수의 분포 형태에 대해서는 특별한 가정은 없다. 하지만 꼬리가 지나치게 긴 분포의 경우에는 대략 좌우대칭이 될 수 있도록 변환을 시키는 것이 좋다. 변수 income과 infant를 로그변환시키고 다시 산점도행렬을 작성해 보자. Leinhardt_ln &lt;- Leinhardt |&gt; mutate(ln_income = log(income), ln_infant = log(infant), .before = 1) |&gt; select(-income, -infant) Leinhardt_ln |&gt; ggpairs() 그림 4.6: Leinhardt_ln 변수의 산점도 행렬 변수 ln_income과 oil만을 설명변수로 하여 회귀모형을 적합해 보자. 함수 lm()은 요인을 설명변수로 입력하면 자동으로 필요한 개수의 가변수를 생성한다. lm(ln_infant ~ ln_income + oil, Leinhardt_ln) ## ## Call: ## lm(formula = ln_infant ~ ln_income + oil, data = Leinhardt_ln) ## ## Coefficients: ## (Intercept) ln_income oilyes ## 7.1396 -0.5211 0.7900 변수 oil의 수준은 'no'와 'yes'의 두 가지이지만 모형에 포함된 가변수는 한 개이다. 이것은 절편이 모형에 포함된 상태에서 요인의 수준 개수만큼 가변수를 포함시키면 회귀계수 전체를 추정할 수 없는 문제가 발생하기 때문이다. 생략된 가변수는 알파벳 순서에서 첫 번째 범주인 'no'에 대한 것이며, 이 범주가 기준 범주가 된다. 범주 'yes'에 대한 가변수의 회귀계수는 기준 범주와의 효과 차이를 나타낸 것이며, 양의 값으로 추정되었으므로 'yes' 범주의 신생아 사망률이 더 높다고 해석할 수 있다. 하지만 이러한 해석은 산유국의 신생아 사망률이 더 높다는 의미가 되는 것이기 때문에 정확한 이유를 확인할 필요가 있다고 보인다. 이 문제는 4.2절에서 예제로 다시 살펴보겠다. 설명변수를 모두 포함한 회귀모형을 적합해 보자. lm(ln_infant ~ ln_income + oil + region, Leinhardt_ln) ## ## Call: ## lm(formula = ln_infant ~ ln_income + oil + region, data = Leinhardt_ln) ## ## Coefficients: ## (Intercept) ln_income oilyes regionAmericas regionAsia ## 6.5521 -0.3398 0.6402 -0.5498 -0.7129 ## regionEurope ## -1.0338 변수 region의 기준범주는 'Africa'가 이며, region에 대한 모든 가변수의 회귀계수가 음수로 추정되었다는 것은 다른 모든 지역이 'Africa' 지역보다 신생아 사망률이 더 낮다는 것을 의미한다. 4.2 다중회귀모형의 추론 4.1절에서 우리는 다항회귀모형과 가변수 회귀모형 등 몇 가지 형태의 다중회귀모형을 살펴보았고, 최소제곱추정량에 의한 회귀계수의 추정 방법도 살펴보았다. 지금부터는 회귀계수의 추론에 대해 살펴보도록 하자. 반응변수와 설명변수에 대해 자료가 관측되면 회귀모형에 대한 다양한 추론을 할 수 있는데, 이러한 추론을 진행하기 위해서는 회귀계수의 추정량에 대한 표본분포를 알아야 한다. 4.2.1 회귀계수 추정량의 표본분포 다중회귀모형은 다음과 같이 행렬의 형태로 나타내는 것이 일반적인 표현 방식이 된다. \\[\\begin{equation} \\mathbf{Y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon} \\end{equation}\\] 반응변수 벡터 \\(\\mathbf{Y}\\) 와 설명변수 관찰값 행렬 \\(\\mathbf{X}\\), 모수 벡터 \\(\\boldsymbol{\\beta}\\), 오차항 벡터 \\(\\boldsymbol{\\varepsilon}\\) 의 정의는 식 (4.2) 에서 볼 수 있다. 또한 오차항 \\(\\varepsilon_{i}, ~i=1,\\ldots,n\\) 이 모두 평균이 \\(0\\), 분산이 \\(\\sigma^{2}\\) 이며, 서로 독립이라는 가정도 다음과 같이 행렬로 표현할 수 있다. \\[ E(\\boldsymbol{\\varepsilon}) = \\begin{pmatrix} 0 \\\\ 0 \\\\ \\vdots \\\\ 0 \\end{pmatrix} \\] \\[ Var(\\boldsymbol{\\varepsilon}) = \\begin{pmatrix} \\sigma^{2} &amp; 0 &amp; \\cdots &amp; 0 \\\\ 0 &amp; \\sigma^{2} &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; 0 &amp; \\cdots &amp; \\sigma^{2} \\end{pmatrix}= \\sigma^{2}~\\mathbf{I} \\] 단, \\(\\mathbf{I}\\) 는 \\(n\\) 차 단위행렬이다. 오차항 벡터의 가정을 기반으로 반응변수 벡터 \\(\\mathbf{Y}\\) 의 평균과 분산은 다음과 같이 구할 수 있으며, \\[\\begin{equation} E(\\mathbf{Y}) = E(\\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon}) = E(\\mathbf{X}\\boldsymbol{\\beta}) = \\mathbf{X}\\boldsymbol{\\beta} \\end{equation}\\] \\[\\begin{equation} Var(\\mathbf{Y}) = Var(\\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon}) = Var(\\boldsymbol{\\varepsilon}) = \\sigma^{2}~\\mathbf{I} \\end{equation}\\] 오차항이 정규분포한다는 가정을 추가하면 반응변수 벡터 \\(\\mathbf{Y}\\) 의 분포는 다음과 같다. \\[\\begin{equation} \\mathbf{Y} \\sim N(\\boldsymbol{\\beta},~\\sigma^{2}\\mathbf{I}) \\end{equation}\\] 이제 모수 벡터 \\(\\boldsymbol{\\beta}\\) 의 최소제곱추정량 \\(\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^{T}\\mathbf{X})^{-1}\\mathbf{X}^{T}\\mathbf{Y}\\) 의 표본분포를 알아보자. 먼저 추정량 벡터의 평균은 다음과 같이 구할 수 있다. \\[\\begin{align*} E(\\hat{\\boldsymbol{\\beta}}) &amp;= E((\\mathbf{X}^{T}\\mathbf{X})^{-1}\\mathbf{X}^{T}\\mathbf{Y}) \\\\ &amp;= (\\mathbf{X}^{T}\\mathbf{X})^{-1}\\mathbf{X}^{T}E(\\mathbf{Y}) \\\\ &amp;= (\\mathbf{X}^{T}\\mathbf{X})^{-1}\\mathbf{X}^{T}\\mathbf{X}\\boldsymbol{\\beta} \\\\ &amp;= \\boldsymbol{\\beta} \\end{align*}\\] 추정량 벡터의 분산은 다음과 같이 구할 수 있다. \\[\\begin{align*} Var(\\hat{\\boldsymbol{\\beta}}) &amp;= Var((\\mathbf{X}^{T}\\mathbf{X})^{-1}\\mathbf{X}^{T}\\mathbf{Y}) \\\\ &amp;= (\\mathbf{X}^{T}\\mathbf{X})^{-1}\\mathbf{X}^{T}~Var(\\mathbf{Y})~ ((\\mathbf{X}^{T}\\mathbf{X})^{-1}\\mathbf{X}^{T})^{T} \\\\ &amp;= (\\mathbf{X}^{T}\\mathbf{X})^{-1}\\mathbf{X}^{T}~\\sigma^{2}\\mathbf{I}~ ((\\mathbf{X}^{T}\\mathbf{X})^{-1}\\mathbf{X}^{T})^{T} \\\\ &amp;= \\sigma^{2} (\\mathbf{X}^{T}\\mathbf{X})^{-1}\\mathbf{X}^{T} \\mathbf{X} (\\mathbf{X}^{T}\\mathbf{X})^{-1} \\\\ &amp;= \\sigma^{2} (\\mathbf{X}^{T}\\mathbf{X})^{-1} \\end{align*}\\] 또한 \\(\\hat{\\boldsymbol{\\beta}}\\) 은 반응변수 벡터 \\(\\mathbf{Y}\\) 의 선형결합으로 표시되기 때문에 \\(\\mathbf{Y}\\) 와 같은 정규분포를 하게 된다. 따라서 추정량 벡터의 표본분포는 다음과 같이 주어진다. \\[\\begin{equation} \\hat{\\boldsymbol{\\beta}} \\sim N\\left(\\boldsymbol{\\beta},~\\sigma^{2} (\\mathbf{X}^{T}\\mathbf{X})^{-1}\\right) \\tag{4.15} \\end{equation}\\] 또한 개별 추정량의 분포는 다음과 같이 주어진다. \\[\\begin{equation} \\hat{\\beta}_{j} \\sim N(\\beta_{j},~c_{j+1,j+1}~\\sigma^{2}),~~j=0,1,\\ldots,k \\tag{4.16} \\end{equation}\\] 단, \\(c_{i, j}\\)은 \\((\\mathbf{X}^{T}\\mathbf{X})^{-1}\\) 행렬의 \\(i\\) 번째 행, \\(j\\) 번째 열 원소를 나타낸다. 식 (4.15)에 주어진 추정량 벡터의 표본분포를 이용해서 추론을 실시하기 위해서는 오차항 분산인 \\(\\sigma^{2}\\) 에 대한 추정값이 반드시 필요하다. 2.2.3절에서 단순회귀모형의 경우에 적용되는 오차항 분산의 추정량 \\(MSE\\) 가 식 (2.17)으로 유도되는 것을 살펴보았다. 단순회귀모형의 경우 잔차제곱합 \\(RSS\\)의 자유도가 \\((n-2)\\) 가 된 이유는 \\(\\widehat{Y}_{i}\\) 을 얻기 위해 추정해야할 모수의 개수가 2개이기 때문이다. 다중회귀모형에서는 추정해야 할 모수가 \\(\\beta_{0}, \\beta_{1}, \\ldots, \\beta_{k}\\) 의 \\((k+1)\\) 개가 있고, 따라서 \\(RSS\\)의 자유도는 \\((n-k-1)\\) 이 되어서 \\(\\sigma^{2}\\) 의 불편추정량 \\(MSE\\) 는 다음과 같이 주어진다. \\[\\begin{equation} \\hat{\\sigma}^{2} = \\frac{RSS}{n-k-1} = MSE \\tag{4.17} \\end{equation}\\] 식 (4.17)의 \\(MSE\\) 는 \\(k=1\\) 인 단순회귀모형의 경우도 포괄하는 일반적인 정의가 된다. 4.2.2 회귀모형의 유의성 검정 식 (4.1)의 회귀모형에 포함된 설명변수 중 반응변수의 변동을 설명하는데 유의적인 변수가 적어도 하나라도 있는지 알아보는 검정이다. 귀무가설은 다음과 같고, \\[\\begin{equation} H_{0}:\\beta_{1}=\\beta_{2}=\\cdots=\\beta_{k}=0 \\tag{4.18} \\end{equation}\\] 대립가설은 다음과 같다. \\[\\begin{equation} H_{1}: \\text{at least one of }\\beta_{j} \\ne 0 \\end{equation}\\] 가설에 대한 검정통계량은 다음과 같다. \\[\\begin{equation} F = \\frac{(TSS-RSS)/k}{RSS/(n-k-1)} \\end{equation}\\] 귀무가설이 사실일 때 검정통게량의 분포는 \\(F_{k,~n-k-1}\\) 이다. 검정통계량의 구성을 살펴보자. \\(TSS=\\sum(y_{i}-\\overline{y})^{2}\\) 는 반응변수의 총변량으로써 설명변수와는 관련이 없는 변량이다. \\(RSS = \\sum(y_{i}-\\hat{y}_{i})^{2}\\) 는 잔차제곱합으로써 \\(y_{i}\\) 를 \\(\\hat{y}_{i}\\) 으로 예측한 오차이며, 회귀모형으로 설명이 안 된 변량이라고 할 수 있다. 따라서 총변량에서 설명이 안 된 변량을 제외한 \\(TSS-RSS\\) 는 회귀모형으로 설명된 변량이라고 할 수 있다. 검정통계량의 분모는 \\(RSS\\)를 자신의 자유도 \\((n-k-1)\\) 로 나눈 것인데, 이것은 회귀모형의 가정이 만족되는 경우에는 귀무가설의 사실 여부와 관계 없이 오차항의 분산인 \\(\\sigma^{2}\\)의 불편추정량이 된다. 즉, \\(E(RSS/(n-k-1))=\\sigma^{2}\\) 가 된다. 검정통계량의 분자인 \\((TSS-RSS)/k\\) 는 \\(H_{0}\\) 이 사실인 경우에는 \\(\\sigma^{2}\\) 의 불편추정량이 되지만, \\(H_{0}\\) 이 사실이 아닌 경우에는 \\(E((TSS-RSS)/k) &gt; \\sigma^{2}\\) 가 된다. 따라서 검정통계량이 1보다 상당히 큰 값이 되면 \\(H_{0}\\)이 사실이 아닐 가능성이 높게 되며, 기각역은 자유도가 \\((k, ~n-k-1)\\) 인 \\(F\\) 분포에서 결정된다. 가설 (4.18)이 기각되면 모형에 포함된 설명변수 중 유의한 변수가 있다는 것이므로, 개별 회귀계수에 대한 유의성 검정을 진행할 수 있다. 그러나 만일 가설을 기각할 수 없다면 식 (4.1)의 회귀모형으로는 반응변수의 변동을 제대로 설명할 수 없다는 것이 된다. 이런 결과가 나오면, 다른 설명변수의 조합을 찾아 보거나, 또는 다른 형태의 회귀모형을 시도해 봐야 한다. 4.2.3 개별회귀계수 유의성 검정 식 (4.1)에 정의된 회귀모형을 구성하고 있는 개별 설명변수의 유의성을 검정하는 절차이다. 가설은 다음과 같다. \\[\\begin{equation} H_{0}: \\beta_{j} = 0, \\quad H_{1}: \\beta_{j} \\ne 0, \\quad j = 1, \\ldots, k \\tag{4.19} \\end{equation}\\] 검정통계량은 개별 회귀계수의 추정량 \\(\\hat{\\beta}_{j}\\) 를 추정량의 표준오차로 나눈 것이다. \\[\\begin{equation} t = \\frac{\\hat{\\beta}_{j}}{SE(\\hat{\\beta}_{j})} \\end{equation}\\] 단, \\(SE(\\hat{\\beta}_{j}) = \\sqrt{c_{j+1,j+1}~MSE}\\) 이며, \\(c_{j+1, j+1}\\) 은 (4.16)에 정의되어 있다. 귀무가설이 사실일 때 검정통계량의 분포는 \\(t_{n-k-1}\\) 이다. 개별 회귀계수에 대한 검정은 양측검정이 되며, 따라서 회귀계수의 신뢰구간과 밀접한 관련이 있다. 개별 회귀계수에 대한 95% 신뢰구간은 회귀계수와 추정량과 추정량의 표준오차를 이용하여 대략적으로 다음과 같이 표시된다. \\[\\begin{equation} \\hat{\\beta}_{j} \\pm 2 \\cdot SE(\\hat{\\beta}_{j}) \\end{equation}\\] 만일 주어진 자료를 근거로 계산된 \\(\\beta_{j}\\) 의 95% 신뢰구간에 0이 포함되어 있다면, 같은 자료로 계산한 검정통계량의 값은 5% 유의수준으로 구성된 기각역에 들어갈 수 없게 되어서 귀무가설을 기각할 수 없게 된다. 4.2.4 두 회귀모형의 비교 반응변수의 변동을 설명하는데 식 (4.1) 회귀모형의 설명변수를 모두 사용하는 것이 좋은지 아니면 일부분만을 사용하는 것이 더 좋은지 비교하는 절차이다. 비교하는 두 모형은 확장모형( \\(\\Omega\\) )인 모형 (4.1)과 특정 \\(q\\) 개의 회귀계수에 대한 다음의 가설이 사실인 축소모형( \\(\\omega\\) )이다. \\[\\begin{equation} H_{0}: \\beta_{k-q+1}=\\beta_{k-q+2}=\\cdots=\\beta_{k}=0 \\tag{4.20} \\end{equation}\\] 두 모형의 설명력 차이가 크지 않다면 ’모수절약의 원칙’에 의하여 축소모형을 선택하는 것이 더 좋을 것이다. 모형의 설명력 비교는 잔차제곱합을 이용할 수 있는데, 만일 확장모형의 잔차제곱합, \\(RSS_{\\Omega}\\) 와 축소모형의 잔차제곱합, \\(RSS_{\\omega}\\) 의 차이가 크지 않다면, 축소모형의 설명력이 확장모형 만큼 좋다는 의미가 된다. 검정통계량은 다음과 같이 구성된다. \\[\\begin{equation} F=\\frac{(RSS_{\\omega}-RSS_{\\Omega})/q}{RSS_{\\Omega}/(n-k-1)} \\end{equation}\\] 귀무가설이 사실일 때 검정통게량의 분포는 \\(F_{q,~n-k-1}\\) 이다. \\(\\bullet\\) 예제 4.5 : 행렬 state.x77 4.1.1에서 다루었던 state.x77 자료에 대한 분석을 다시 실행해 보자. 앞서 이루어진 분석은 다음과 같다. states &lt;- as_tibble(state.x77) |&gt; rename(Life_Exp = `Life Exp`, HS_Grad = `HS Grad`) |&gt; relocate(Murder, .after = last_col()) fit4.2 &lt;- lm(Murder ~ ., data = states) 이제 lm()으로 생성된 객페 fit4.2를 대상으로 회귀모형 추론을 위한 몇 가지 함수를 적용해 보자. 먼저 가장 빈번하게 사용되는 함수인 summary()의 결과를 확인해 보자. summary(fit4.2) ## ## Call: ## lm(formula = Murder ~ ., data = states) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.4452 -1.1016 -0.0598 1.1758 3.2355 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.222e+02 1.789e+01 6.831 2.54e-08 *** ## Population 1.880e-04 6.474e-05 2.905 0.00584 ** ## Income -1.592e-04 5.725e-04 -0.278 0.78232 ## Illiteracy 1.373e+00 8.322e-01 1.650 0.10641 ## Life_Exp -1.655e+00 2.562e-01 -6.459 8.68e-08 *** ## HS_Grad 3.234e-02 5.725e-02 0.565 0.57519 ## Frost -1.288e-02 7.392e-03 -1.743 0.08867 . ## Area 5.967e-06 3.801e-06 1.570 0.12391 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.746 on 42 degrees of freedom ## Multiple R-squared: 0.8083, Adjusted R-squared: 0.7763 ## F-statistic: 25.29 on 7 and 42 DF, p-value: 3.872e-13 함수 lm()으로 생성된 객체에 함수 summary()를 적용시켜 얻은 결과물은 SAS나 SPSS에서 볼 수 있는 결과물과는 형식에서 차이가 있으나 많은 정보를 매우 효과적으로 보여주는 방식이라고 할 수 있다. 결과물을 하나씩 살펴보자. 먼저 Residuals:에는 잔차의 분포를 엿볼 수 있는 요약통계가 계산되어 있다. 가정이 만족된다면 잔차는 평균이 0인 정규분포를 보이게 되는데, 잔차의 요약 통계 결과 값으로 대략적인 판단을 할 수 있다. Coefficients:에는 회귀계수의 추정값과 표준오차가 계산되어 있다. 또한 개별 회귀계수의 유의성 검정인 \\(H_{0}:\\beta_{j} = 0, \\quad H_{1}: \\beta_{j} \\ne 0\\) 에 대한 검정통계량의 값과 p-값이 계산되어 있다 Residual standard error:는 \\(\\sqrt{MSE}\\) 이며, Multiple R-squared:는 결정계수 \\(R^{2}\\) 이고, Adjusted R-squared:는 수정결정계수의 값으로서, 모두 회귀모형의 평가 측도로 사용된다. 회귀모형의 평가측도에 대해서는 4.3절에서 살펴보겠다. F-statistic:은 모든 회귀계수가 0이라는 가설, 즉 \\(H_{0}:\\beta_{1}=\\beta_{2}=\\cdots=\\beta_{k}=0\\) 에 대한 검정통계량의 값과 자유도, 그리고 p-값이 계산되어 있다. 4.3 변수선택 "],["reg-diag.html", "5 장 회귀모형의 진단", " 5 장 회귀모형의 진단 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
